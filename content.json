{"meta":{"title":"sfysoft","subtitle":"Oak Chen的个人博客","description":"BSP|Kernel|Linux驱动|Ubuntu|Docker|Android","author":"Oak Chen","url":"https://www.sfysoft.com"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2023-08-02T00:59:54.689Z","updated":"2023-08-02T00:59:54.689Z","comments":false,"path":"/404.html","permalink":"https://www.sfysoft.com//404.html","excerpt":"","text":""},{"title":"分类","date":"2023-08-02T00:59:54.701Z","updated":"2023-08-02T00:59:54.701Z","comments":false,"path":"categories/index.html","permalink":"https://www.sfysoft.com/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-08-02T00:59:54.701Z","updated":"2023-08-02T00:59:54.701Z","comments":false,"path":"repository/index.html","permalink":"https://www.sfysoft.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-08-02T00:59:54.701Z","updated":"2023-08-02T00:59:54.701Z","comments":false,"path":"tags/index.html","permalink":"https://www.sfysoft.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Windows 2003使用问题与解决方法","slug":"Windows-2003-Issues-and-Solution","date":"2024-03-18T16:00:00.000Z","updated":"2024-03-18T16:00:00.000Z","comments":true,"path":"2024/03/18/Windows-2003-Issues-and-Solution/","link":"","permalink":"https://www.sfysoft.com/2024/03/18/Windows-2003-Issues-and-Solution/","excerpt":"","text":"Windows Server 2003一度是我最喜欢使用的操作系统，使用的时间可能也是最长。Windows Server 2003是2003年3月28日发布的，并已于2015年终止支持，在20多年后的今天来使用它，多少会有一些问题，好在当初已经预见到这一系统终止支持后，运行在它之上的软件会很难找，因此早已将一些常用的软件保存了可用版本。出于研究一些软件的需要，最近又将这个系统安装在虚拟机中，本文记录一些使用过程中遇到的问题及其解决办法，如无特别提及，本文所说环境为Windows Server 2003 R2 SP2。 远程桌面访问到物理桌面 不同于后来的Windows 7等操作系统，在使用远程桌面连接到Windows Server 2003时，默认连接的是类似于VNC一类工具提供的虚拟桌面，显示的内容和物理桌面是不同的，远程桌面用户和本地用户同时登录时，各自在使用自己的桌面，不能共享。但Windows Server 2003已经支持了连接到物理桌面的功能，若客户端为Windows的远程桌面连接程序，只需要在执行mstsc命令时，加上/console选项（Windows 7之前操作系统）或/admin选项（Windows 7以后操作系统）即可。可以在保存远程桌面的配置文件时，将这选项加在连接目标后面，示例：在Windows.rdp文件的计算机这一栏中，填写192.168.1.2:3389 /admin。如果是在Linux系统上使用Remmina来连接，则可在连接配置文件的&quot;Advanced&quot;标签页内，选上&quot;Attach to console(2003/2003 R2)&quot;。 使用远程桌面连接或Remmina登录时，即使连接到物理桌面，也属于远程用户，可以打开“管理工具”，“终端服务管理器”，“这台计算机”，“会话”，查看会话类型为“RDP-TCP”并且状态为“运行中”的会话。如果要断开远程登录用户的会话，可在此界面选中会话，点击鼠标右键，选择“断开”。 不管是通过远程登录，还是本地控制台登录，物理桌面只允许一个会话，新的登录会将前面正在连接的会话断开。 对于不连接到物理桌面的登录，可以通过“管理工具”，“终端服务配置”，“服务器设置”，“限制每个用户使用一个会话”来使得同一用户只能远程连接到一个会话，这样从不同终端登录时，新的登录会将前面正在连接的会话断开，而桌面内容维持。 Windows 7以上系统连接Windows 2003远程桌面很卡 从Vista开始，微软在TCP/IP协议栈里新加了一个叫做“Window Auto-Tuning”的功能。这个功能本身的目的是为了让操作系统根据网络的实时性能（比如响应时间）来动态调整网络上传输的数据窗口的大小，从而达到实时优化网络性能的目的。但这个功能可能会使远程桌面到Windows 2003时，响应变得非常慢。通过把autotuninglevel设置成disabled，就可以让数据窗口保持默认值。如果设置成highlyrestriected的话，那么就是让系统非常保守地来调整这个数据窗口大小。 设置命令如下: 1netsh interface tcp set global autotuninglevel=disabled 浏览网页时提示证书无效的问题 如下图所示“NET::ERR_CERT_INVALID”，即使点击“重新加载”，依然是一样的提示，或是提示“您计算机的日期和时间不正确，因此无法与XXX建立私密连接。NET::ERR_CERT_DATE_INVALID”，然而，即使更新了计算机的日期和时间为当前最新后，也还是一样的提示。实际上，这都是因为系统证书已经过期很久了，而现在已经无法自动更新。 在仍受支持的Windows操作系统中，系统更新功能会适时更新根证书。因此，在以前，可以从一台更新到最新的Windows系统上，将其证书导出，并导入到Windows 2003中。在Windows 11中，可以使用如下的命令来生成一个包含根证书集的文件： 1certutil.exe -generateSSTFromWU roots.sst 然后将生成的roots.sst文件复制到需要更新证书的系统上，例如复制在C:\\Temp目录，此时需要使用到一个名为rootsupd的工具来完成升级，这工具由Microsoft提供，但现在已经不能从Microsoft网站下载，一个可用的版本来自于杀毒软件厂商卡巴斯基。将此工具下载后，在命令行中执行如下命令，当提示是否覆盖文件时，选择“否” 1rootsupd.exe /C /T:C:\\Temp 完成后，确认C:\\Temp已经存在updroots.exe程序，然后执行如下命令来安装证书： 12cd C:\\Tempupdroots.exe roots.sst 然而时至今日，即使信任的根证书得到更新，浏览器验证证书时，也使用了更高等级的加密协议，而新安装的Windows 2003系统仅支持到TLS 1.0、SSL 2.0、SSL 3.0，依然会提示证书无效。此时，一个可选的办法是：访问https://legacyupdate.net网站来为旧系统获得更新。此网站不仅提供了Windows Update功能，也解决了证书的问题。只是首次使用的时候，检测和安装更新可能会有点久。 参考资料 使用终端服务连接到控制台会话","categories":[{"name":"Windows使用","slug":"Windows使用","permalink":"https://www.sfysoft.com/categories/Windows使用/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://www.sfysoft.com/tags/Windows/"}],"keywords":[{"name":"Windows使用","slug":"Windows使用","permalink":"https://www.sfysoft.com/categories/Windows使用/"}]},{"title":"ClangFormat实践","slug":"ClangFormat-Practices","date":"2022-05-10T14:40:55.000Z","updated":"2023-09-14T05:55:05.339Z","comments":true,"path":"2022/05/10/ClangFormat-Practices/","link":"","permalink":"https://www.sfysoft.com/2022/05/10/ClangFormat-Practices/","excerpt":"","text":"clang-format的使用 使用预定义的编码风格 12clang-format -i hello.c # 若当前目录下存在.clang-format文件时，使用.clang-format定义的编码风格格式化hello.c，否则使用预定义的LLVM编码风格格式化hello.cclang-format -i --style=Google hello.c # 使用预定义的Google编码风格格式化hello.c 使用文件中定义的编码风格 12clang-format -i --style=file hello.c # 使用当前或父目录中的.clang-format文件中定义的编码风格格式化hello.cclang-format -i --style=file:stylePath hello.c # 使用stylePath文件中定义的编码风格格式化hello.c，stylePath可以是绝对或相对路径 生成和自定义配置 使用–dump-config选项，可以生成所使用的clang-format版本支持的所有配置项，然后可以参考Clang-Format Style Options定制自己想要的，如下命令生成Google编码风格的配置： 1clang-format --style=google --dump-config &gt; .clang-format 实例：自定义Linux Kernel的格式化配置文件 自2018年4月起，Linux Kernel的源代码里已经增加了一个.clang-format文件，按照Linux kernel coding style来定制了clang-format的格式化选项。但这仍存在几个问题： 没有指定确定的clang-format版本，仅说明在4.0版本以上，然而，更高版本的clang-format可能会不再支持某些配置项（这问题可以通过指定–Wno-error=unknown来解决），更糟糕的是某些配置项的类型改变了，例如：原来的配置项是布尔型的，支持的是true或false，在新的版本里，可能变成了枚举类型以支持多样性，此时，配置文件必须修改才能使用。从内核自带的.clang-format文件中，存在多个配置项被注释掉也能看得出来 内核自带的.clang-format并没有利用上新版本的clang-format的更多特性，这些新特性可能使得格式化操作更贴合内核编码风格的需求 为此，我们可以分几步对此进行改进： 1.首先选定所使用的clang-format版本，截止此时的稳定发行版为clang-format 14.0 2.复制内核原有的.clang-format为.clang-format-14 3.使用clang-format --style=Google --dump-config &gt; .clang-format-google生成一个预定义的配置文件 4.比较.clang-format-14和.clang-format-google可以看到有很多配置不同，但我们仅关注类型改变了的，及.clang-format-14缺少了的配置项，例如AlignConsecutiveAssignments在.clang-format-14中是boolean型的false，在.clang-format-google却是None，这种属于类型改变。而AlignConsecutiveMacros则是.clang-format-14中缺少的配置项。根据文件比较出来的不同，及Clang-Format Style Options的描述，在不改变.clang-format-14原有配置项的含义和内核编码风格的前提下，按需把配置项的值转换为新类型的，并加上缺少的部分，就形成了一个完整的适配于clang-format 14.0的版本 5.之后可以用clang-format -i --style=file:&lt;path-to-.clang-format-14&gt; file.c命令来格式化内核代码 以下是本人的配置范例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678# 用于Linux Kernel的clang-format配置文件，验证的clang-format版本为14.0## Copyright (C) 2022-2022 Oak Chen &lt;oak@sfysoft.com&gt;# # 本配置文件基于Linux Kernel v5.16-rc5-90-gef8dd01538ea自带的.clang-format，# 再使用clang-format 14.0版本，以--dump-config --style=Google# 生成配置，整合缺少的配置，适配为clang-format 14版本，并增加注释而成## 更多的信息可以参考# Documentation/process/clang-format.rst# https://clang.llvm.org/docs/ClangFormat.html# https://clang.llvm.org/docs/ClangFormatStyleOptions.html#---# BasedOnStyle: InheritParentConfigAccessModifierOffset: -4 # 访问修饰符（如public）的缩进或凸出AlignAfterOpenBracket: Align # 在开括号处对齐参数AlignArrayOfStructures: None # 初始化结构体里面的数组时，对齐表达式的值，clang-format 13AlignConsecutiveAssignments: None # 对齐连续赋值时的赋值符AlignConsecutiveBitFields: None # 对齐连续的位域分隔符（即:），clang-format 11AlignConsecutiveDeclarations: None # 对齐连续定义的变量名AlignConsecutiveMacros: None # 对齐连续宏定义时的值，clang-format 9AlignEscapedNewlines: Left # 对齐\\续行时的\\，clang-format 5AlignOperands: Align # 对齐分成多行的表达式的操作数AlignTrailingComments: false # 对齐行尾的注释AllowAllArgumentsOnNextLine: false # 允许所有实参在下一行，clang-format 9AllowAllParametersOfDeclarationOnNextLine: false # 允许定义时的所有参数在下一行AllowShortBlocksOnASingleLine: Never # 允许短代码块写在一行AllowShortCaseLabelsOnASingleLine: false # 允许短的case标签写在一行AllowShortEnumsOnASingleLine: false # 允许短的枚举值在同一行AllowShortFunctionsOnASingleLine: None # 允许短函数写在一行AllowShortIfStatementsOnASingleLine: Never # 允许短的if语句写在一行AllowShortLambdasOnASingleLine: All # 允许短的lambda表达式写在一行，clang-format 9AllowShortLoopsOnASingleLine: false # 允许短循环写在一行AlwaysBreakAfterDefinitionReturnType: None # 函数定义处的返回类型后是否换行AlwaysBreakAfterReturnType: None # 函数声明处的返回类型后是否换行AlwaysBreakBeforeMultilineStrings: false # 多行拼接的字符串前是否换行，即字符串的起始行是否另起一行AlwaysBreakTemplateDeclarations: Yes # 模板定义时，是否在定义前换行，clang-format 7AttributeMacros: # 可视为属性或限定符的宏，常用于编译器扩展，clang-format 12 - __capabilityBinPackArguments: true # 函数调用时，参数尽可能在同一行，false为每行一个参数BinPackParameters: true # 函数定义时，参数尽可能在同一行，false为每行一个参数BitFieldColonSpacing: Both # 位域:前后加空格，clang-format 12BraceWrapping: # 自定义的&#123;换行规则 AfterCaseLabel: false # 在case标签后换行 AfterClass: false # 在class后换行 AfterControlStatement: Never # 在控制语句后换行 AfterEnum: false # 在枚举定义后换行 AfterFunction: true # 在函数定义后换行 AfterNamespace: true # 在命名空间定义后换行 AfterObjCDeclaration: false # 在Objective C定义（接口、实现等）后换行 AfterStruct: false # 在结构体定义后换行 AfterUnion: false # 在联合体定义后换行 AfterExternBlock: false # 在extern \"C\"这种声明后换行，clang-format 11 BeforeCatch: false # 在catch语句前换行 BeforeElse: false # 在else语句前换行 BeforeLambdaBody: false # 在lambda定义体前换行 BeforeWhile: false # 在do while的while前换行 IndentBraces: false # 缩进&#123; SplitEmptyFunction: true # 拆分空的函数体 SplitEmptyRecord: true # 拆分空的class、struct、union等定义 SplitEmptyNamespace: true # 拆分空的namespace定义BreakAfterJavaFieldAnnotations: false # 在Java的注解器后换行BreakBeforeBinaryOperators: None # 在二元操作符前换行BreakBeforeBraces: Custom # 自定义&#123;前的换行，规则由BraceWrapping指定BreakBeforeConceptDeclarations: true # 在concept前换行，clang-format 12BreakBeforeInheritanceComma: false # 继承时，在,前换行，clang-format 15不支持BreakBeforeTernaryOperators: false # 在三行表达式的操作符前换行BreakConstructorInitializersBeforeComma: false # 在构造器的初始化列表前的:前换行，已被BreakConstructorInitializers取代BreakConstructorInitializers: BeforeComma # 在构造器的初始化列表中，在:和,前换行，并对齐:和,，clang-format 5BreakInheritanceList: BeforeColon # 使用继承列表时，在:前换行，clang-format 7BreakStringLiterals: false # 字符串字面值折成多行ColumnLimit: 80 # 以单字节字符为单位的列宽度限制CommentPragmas: '^ IWYU pragma:' # 注释里面的特别含义指示行，这里面包含的行不会被拆分CompactNamespaces: false # 合并连续的命名空间定义到一行，clang-format 5ConstructorInitializerAllOnOneLineOrOnePerLine: false # 构造器的初始化列表写在一行还是每个初始值一行ConstructorInitializerIndentWidth: 8 # 构造器初始化列表缩进宽度ContinuationIndentWidth: 8 # 连续缩进宽度Cpp11BracedListStyle: false # 使用C++11的大括号里面的值列表风格，主要是第一个值前面和最后一个值后不加空格DeriveLineEnding: false # 分析待格式化的文件以发现最常用的行结尾符，若不确定，则使用“\\r\\n”，clang-format 10DerivePointerAlignment: false # 分析待格式化的文件以发现最常用的指针对齐风格，若不确定，则使用PointerAlignment的定义DisableFormat: false # 完全禁止格式化EmptyLineAfterAccessModifier: Never # 访问修饰符（public等）后添加空行，clang-format 13EmptyLineBeforeAccessModifier: LogicalBlock # 访问修饰符（public等）前添加空行，clang-format 12ExperimentalAutoDetectBinPacking: false # 检测函数定义和调用时，是否一个参数占用一行FixNamespaceComments: false # 为较短的namespace添加缺失的结束注释（// namespace X），怎样的视为“短”由ShortNamespaceLines控制，clang-format 5# Taken from:# git grep -h '^#define [^[:space:]]*for_each[^[:space:]]*(' include/ \\# | sed \"s,^#define \\([^[:space:]]*for_each[^[:space:]]*\\)(.*$, - '\\1',\" \\# | sort | uniqForEachMacros: # 视为foreach循环而非函数调用的宏 - 'apei_estatus_for_each_section' - 'ata_for_each_dev' - 'ata_for_each_link' - '__ata_qc_for_each' - 'ata_qc_for_each' - 'ata_qc_for_each_raw' - 'ata_qc_for_each_with_internal' - 'ax25_for_each' - 'ax25_uid_for_each' - '__bio_for_each_bvec' - 'bio_for_each_bvec' - 'bio_for_each_bvec_all' - 'bio_for_each_integrity_vec' - '__bio_for_each_segment' - 'bio_for_each_segment' - 'bio_for_each_segment_all' - 'bio_list_for_each' - 'bip_for_each_vec' - 'bitmap_for_each_clear_region' - 'bitmap_for_each_set_region' - 'blkg_for_each_descendant_post' - 'blkg_for_each_descendant_pre' - 'blk_queue_for_each_rl' - 'bond_for_each_slave' - 'bond_for_each_slave_rcu' - 'bpf_for_each_spilled_reg' - 'btree_for_each_safe128' - 'btree_for_each_safe32' - 'btree_for_each_safe64' - 'btree_for_each_safel' - 'card_for_each_dev' - 'cgroup_taskset_for_each' - 'cgroup_taskset_for_each_leader' - 'cpufreq_for_each_entry' - 'cpufreq_for_each_entry_idx' - 'cpufreq_for_each_valid_entry' - 'cpufreq_for_each_valid_entry_idx' - 'css_for_each_child' - 'css_for_each_descendant_post' - 'css_for_each_descendant_pre' - 'device_for_each_child_node' - 'displayid_iter_for_each' - 'dma_fence_chain_for_each' - 'do_for_each_ftrace_op' - 'drm_atomic_crtc_for_each_plane' - 'drm_atomic_crtc_state_for_each_plane' - 'drm_atomic_crtc_state_for_each_plane_state' - 'drm_atomic_for_each_plane_damage' - 'drm_client_for_each_connector_iter' - 'drm_client_for_each_modeset' - 'drm_connector_for_each_possible_encoder' - 'drm_for_each_bridge_in_chain' - 'drm_for_each_connector_iter' - 'drm_for_each_crtc' - 'drm_for_each_crtc_reverse' - 'drm_for_each_encoder' - 'drm_for_each_encoder_mask' - 'drm_for_each_fb' - 'drm_for_each_legacy_plane' - 'drm_for_each_plane' - 'drm_for_each_plane_mask' - 'drm_for_each_privobj' - 'drm_mm_for_each_hole' - 'drm_mm_for_each_node' - 'drm_mm_for_each_node_in_range' - 'drm_mm_for_each_node_safe' - 'flow_action_for_each' - 'for_each_acpi_dev_match' - 'for_each_active_dev_scope' - 'for_each_active_drhd_unit' - 'for_each_active_iommu' - 'for_each_aggr_pgid' - 'for_each_available_child_of_node' - 'for_each_bio' - 'for_each_board_func_rsrc' - 'for_each_bvec' - 'for_each_card_auxs' - 'for_each_card_auxs_safe' - 'for_each_card_components' - 'for_each_card_dapms' - 'for_each_card_pre_auxs' - 'for_each_card_prelinks' - 'for_each_card_rtds' - 'for_each_card_rtds_safe' - 'for_each_card_widgets' - 'for_each_card_widgets_safe' - 'for_each_cgroup_storage_type' - 'for_each_child_of_node' - 'for_each_clear_bit' - 'for_each_clear_bit_from' - 'for_each_cmsghdr' - 'for_each_compatible_node' - 'for_each_component_dais' - 'for_each_component_dais_safe' - 'for_each_comp_order' - 'for_each_console' - 'for_each_cpu' - 'for_each_cpu_and' - 'for_each_cpu_not' - 'for_each_cpu_wrap' - 'for_each_dapm_widgets' - 'for_each_dev_addr' - 'for_each_dev_scope' - 'for_each_dma_cap_mask' - 'for_each_dpcm_be' - 'for_each_dpcm_be_rollback' - 'for_each_dpcm_be_safe' - 'for_each_dpcm_fe' - 'for_each_drhd_unit' - 'for_each_dss_dev' - 'for_each_dtpm_table' - 'for_each_efi_memory_desc' - 'for_each_efi_memory_desc_in_map' - 'for_each_element' - 'for_each_element_extid' - 'for_each_element_id' - 'for_each_endpoint_of_node' - 'for_each_evictable_lru' - 'for_each_fib6_node_rt_rcu' - 'for_each_fib6_walker_rt' - 'for_each_free_mem_pfn_range_in_zone' - 'for_each_free_mem_pfn_range_in_zone_from' - 'for_each_free_mem_range' - 'for_each_free_mem_range_reverse' - 'for_each_func_rsrc' - 'for_each_hstate' - 'for_each_if' - 'for_each_iommu' - 'for_each_ip_tunnel_rcu' - 'for_each_irq_nr' - 'for_each_link_codecs' - 'for_each_link_cpus' - 'for_each_link_platforms' - 'for_each_lru' - 'for_each_matching_node' - 'for_each_matching_node_and_match' - 'for_each_member' - 'for_each_memcg_cache_index' - 'for_each_mem_pfn_range' - '__for_each_mem_range' - 'for_each_mem_range' - '__for_each_mem_range_rev' - 'for_each_mem_range_rev' - 'for_each_mem_region' - 'for_each_migratetype_order' - 'for_each_msi_entry' - 'for_each_msi_entry_safe' - 'for_each_net' - 'for_each_net_continue_reverse' - 'for_each_netdev' - 'for_each_netdev_continue' - 'for_each_netdev_continue_rcu' - 'for_each_netdev_continue_reverse' - 'for_each_netdev_feature' - 'for_each_netdev_in_bond_rcu' - 'for_each_netdev_rcu' - 'for_each_netdev_reverse' - 'for_each_netdev_safe' - 'for_each_net_rcu' - 'for_each_new_connector_in_state' - 'for_each_new_crtc_in_state' - 'for_each_new_mst_mgr_in_state' - 'for_each_new_plane_in_state' - 'for_each_new_private_obj_in_state' - 'for_each_node' - 'for_each_node_by_name' - 'for_each_node_by_type' - 'for_each_node_mask' - 'for_each_node_state' - 'for_each_node_with_cpus' - 'for_each_node_with_property' - 'for_each_nonreserved_multicast_dest_pgid' - 'for_each_of_allnodes' - 'for_each_of_allnodes_from' - 'for_each_of_cpu_node' - 'for_each_of_pci_range' - 'for_each_old_connector_in_state' - 'for_each_old_crtc_in_state' - 'for_each_old_mst_mgr_in_state' - 'for_each_oldnew_connector_in_state' - 'for_each_oldnew_crtc_in_state' - 'for_each_oldnew_mst_mgr_in_state' - 'for_each_oldnew_plane_in_state' - 'for_each_oldnew_plane_in_state_reverse' - 'for_each_oldnew_private_obj_in_state' - 'for_each_old_plane_in_state' - 'for_each_old_private_obj_in_state' - 'for_each_online_cpu' - 'for_each_online_node' - 'for_each_online_pgdat' - 'for_each_pci_bridge' - 'for_each_pci_dev' - 'for_each_pci_msi_entry' - 'for_each_pcm_streams' - 'for_each_physmem_range' - 'for_each_populated_zone' - 'for_each_possible_cpu' - 'for_each_present_cpu' - 'for_each_prime_number' - 'for_each_prime_number_from' - 'for_each_process' - 'for_each_process_thread' - 'for_each_prop_codec_conf' - 'for_each_prop_dai_codec' - 'for_each_prop_dai_cpu' - 'for_each_prop_dlc_codecs' - 'for_each_prop_dlc_cpus' - 'for_each_prop_dlc_platforms' - 'for_each_property_of_node' - 'for_each_registered_fb' - 'for_each_requested_gpio' - 'for_each_requested_gpio_in_range' - 'for_each_reserved_mem_range' - 'for_each_reserved_mem_region' - 'for_each_rtd_codec_dais' - 'for_each_rtd_components' - 'for_each_rtd_cpu_dais' - 'for_each_rtd_dais' - 'for_each_set_bit' - 'for_each_set_bit_from' - 'for_each_set_clump8' - 'for_each_sg' - 'for_each_sg_dma_page' - 'for_each_sg_page' - 'for_each_sgtable_dma_page' - 'for_each_sgtable_dma_sg' - 'for_each_sgtable_page' - 'for_each_sgtable_sg' - 'for_each_sibling_event' - 'for_each_subelement' - 'for_each_subelement_extid' - 'for_each_subelement_id' - '__for_each_thread' - 'for_each_thread' - 'for_each_unicast_dest_pgid' - 'for_each_vsi' - 'for_each_wakeup_source' - 'for_each_zone' - 'for_each_zone_zonelist' - 'for_each_zone_zonelist_nodemask' - 'fwnode_for_each_available_child_node' - 'fwnode_for_each_child_node' - 'fwnode_graph_for_each_endpoint' - 'gadget_for_each_ep' - 'genradix_for_each' - 'genradix_for_each_from' - 'hash_for_each' - 'hash_for_each_possible' - 'hash_for_each_possible_rcu' - 'hash_for_each_possible_rcu_notrace' - 'hash_for_each_possible_safe' - 'hash_for_each_rcu' - 'hash_for_each_safe' - 'hctx_for_each_ctx' - 'hlist_bl_for_each_entry' - 'hlist_bl_for_each_entry_rcu' - 'hlist_bl_for_each_entry_safe' - 'hlist_for_each' - 'hlist_for_each_entry' - 'hlist_for_each_entry_continue' - 'hlist_for_each_entry_continue_rcu' - 'hlist_for_each_entry_continue_rcu_bh' - 'hlist_for_each_entry_from' - 'hlist_for_each_entry_from_rcu' - 'hlist_for_each_entry_rcu' - 'hlist_for_each_entry_rcu_bh' - 'hlist_for_each_entry_rcu_notrace' - 'hlist_for_each_entry_safe' - 'hlist_for_each_entry_srcu' - '__hlist_for_each_rcu' - 'hlist_for_each_safe' - 'hlist_nulls_for_each_entry' - 'hlist_nulls_for_each_entry_from' - 'hlist_nulls_for_each_entry_rcu' - 'hlist_nulls_for_each_entry_safe' - 'i3c_bus_for_each_i2cdev' - 'i3c_bus_for_each_i3cdev' - 'ide_host_for_each_port' - 'ide_port_for_each_dev' - 'ide_port_for_each_present_dev' - 'idr_for_each_entry' - 'idr_for_each_entry_continue' - 'idr_for_each_entry_continue_ul' - 'idr_for_each_entry_ul' - 'in_dev_for_each_ifa_rcu' - 'in_dev_for_each_ifa_rtnl' - 'inet_bind_bucket_for_each' - 'inet_lhash2_for_each_icsk_rcu' - 'key_for_each' - 'key_for_each_safe' - 'klp_for_each_func' - 'klp_for_each_func_safe' - 'klp_for_each_func_static' - 'klp_for_each_object' - 'klp_for_each_object_safe' - 'klp_for_each_object_static' - 'kunit_suite_for_each_test_case' - 'kvm_for_each_memslot' - 'kvm_for_each_vcpu' - 'list_for_each' - 'list_for_each_codec' - 'list_for_each_codec_safe' - 'list_for_each_continue' - 'list_for_each_entry' - 'list_for_each_entry_continue' - 'list_for_each_entry_continue_rcu' - 'list_for_each_entry_continue_reverse' - 'list_for_each_entry_from' - 'list_for_each_entry_from_rcu' - 'list_for_each_entry_from_reverse' - 'list_for_each_entry_lockless' - 'list_for_each_entry_rcu' - 'list_for_each_entry_reverse' - 'list_for_each_entry_safe' - 'list_for_each_entry_safe_continue' - 'list_for_each_entry_safe_from' - 'list_for_each_entry_safe_reverse' - 'list_for_each_entry_srcu' - 'list_for_each_prev' - 'list_for_each_prev_safe' - 'list_for_each_safe' - 'llist_for_each' - 'llist_for_each_entry' - 'llist_for_each_entry_safe' - 'llist_for_each_safe' - 'mci_for_each_dimm' - 'media_device_for_each_entity' - 'media_device_for_each_intf' - 'media_device_for_each_link' - 'media_device_for_each_pad' - 'nanddev_io_for_each_page' - 'netdev_for_each_lower_dev' - 'netdev_for_each_lower_private' - 'netdev_for_each_lower_private_rcu' - 'netdev_for_each_mc_addr' - 'netdev_for_each_uc_addr' - 'netdev_for_each_upper_dev_rcu' - 'netdev_hw_addr_list_for_each' - 'nft_rule_for_each_expr' - 'nla_for_each_attr' - 'nla_for_each_nested' - 'nlmsg_for_each_attr' - 'nlmsg_for_each_msg' - 'nr_neigh_for_each' - 'nr_neigh_for_each_safe' - 'nr_node_for_each' - 'nr_node_for_each_safe' - 'of_for_each_phandle' - 'of_property_for_each_string' - 'of_property_for_each_u32' - 'pci_bus_for_each_resource' - 'pcl_for_each_chunk' - 'pcl_for_each_segment' - 'pcm_for_each_format' - 'ping_portaddr_for_each_entry' - 'plist_for_each' - 'plist_for_each_continue' - 'plist_for_each_entry' - 'plist_for_each_entry_continue' - 'plist_for_each_entry_safe' - 'plist_for_each_safe' - 'pnp_for_each_card' - 'pnp_for_each_dev' - 'protocol_for_each_card' - 'protocol_for_each_dev' - 'queue_for_each_hw_ctx' - 'radix_tree_for_each_slot' - 'radix_tree_for_each_tagged' - 'rb_for_each' - 'rbtree_postorder_for_each_entry_safe' - 'rdma_for_each_block' - 'rdma_for_each_port' - 'rdma_umem_for_each_dma_block' - 'resource_list_for_each_entry' - 'resource_list_for_each_entry_safe' - 'rhl_for_each_entry_rcu' - 'rhl_for_each_rcu' - 'rht_for_each' - 'rht_for_each_entry' - 'rht_for_each_entry_from' - 'rht_for_each_entry_rcu' - 'rht_for_each_entry_rcu_from' - 'rht_for_each_entry_safe' - 'rht_for_each_from' - 'rht_for_each_rcu' - 'rht_for_each_rcu_from' - '__rq_for_each_bio' - 'rq_for_each_bvec' - 'rq_for_each_segment' - 'scsi_for_each_prot_sg' - 'scsi_for_each_sg' - 'sctp_for_each_hentry' - 'sctp_skb_for_each' - 'shdma_for_each_chan' - '__shost_for_each_device' - 'shost_for_each_device' - 'sk_for_each' - 'sk_for_each_bound' - 'sk_for_each_entry_offset_rcu' - 'sk_for_each_from' - 'sk_for_each_rcu' - 'sk_for_each_safe' - 'sk_nulls_for_each' - 'sk_nulls_for_each_from' - 'sk_nulls_for_each_rcu' - 'snd_array_for_each' - 'snd_pcm_group_for_each_entry' - 'snd_soc_dapm_widget_for_each_path' - 'snd_soc_dapm_widget_for_each_path_safe' - 'snd_soc_dapm_widget_for_each_sink_path' - 'snd_soc_dapm_widget_for_each_source_path' - 'tb_property_for_each' - 'tcf_exts_for_each_action' - 'udp_portaddr_for_each_entry' - 'udp_portaddr_for_each_entry_rcu' - 'usb_hub_for_each_child' - 'v4l2_device_for_each_subdev' - 'v4l2_m2m_for_each_dst_buf' - 'v4l2_m2m_for_each_dst_buf_safe' - 'v4l2_m2m_for_each_src_buf' - 'v4l2_m2m_for_each_src_buf_safe' - 'virtio_device_for_each_vq' - 'while_for_each_ftrace_op' - 'xa_for_each' - 'xa_for_each_marked' - 'xa_for_each_range' - 'xa_for_each_start' - 'xas_for_each' - 'xas_for_each_conflict' - 'xas_for_each_marked' - 'xbc_array_for_each_value' - 'xbc_for_each_key_value' - 'xbc_node_for_each_array_value' - 'xbc_node_for_each_child' - 'xbc_node_for_each_key_value' - 'zorro_for_each_dev'IfMacros: # 视为条件而非函数调用的宏，clang-format 13 - KJ_IF_MAYBEIncludeBlocks: Preserve # include块拆分和排序，clang-format 7IncludeCategories: # include分类 - Regex: '.*' Priority: 1IncludeIsMainRegex: '(Test)?$' # 在使用IncludeCategories将文件映射为主要的include文件时，允许在此给主要的include文件添加一个后缀，主要的include文件在排序时会放在顶部，clang-format 7IncludeIsMainSourceRegex: '' # clang-format仅对main源文件（具有.c、.cc、.cpp、.c++、.cxx、.m、.mm扩展名）执行“main include file逻辑”，通过这个，可以将其它文件视为main源文件，clang-format 7IndentAccessModifiers: false # 缩进public等访问修饰符，clang-format 13IndentCaseBlocks: true # 缩进case块，clang-format 11IndentCaseLabels: false # 缩进case标签IndentExternBlock: AfterExternBlock # 缩进extern块，clang-format 11IndentGotoLabels: false # 缩进goto标签，clang-format 10IndentPPDirectives: None # 缩进预处理器指令，clang-format 6IndentRequires: false # 在模板中缩进requires子句，clang-format 12，13，14# IndentRequiresClause: false # 在模板中缩进requires子句，是IndentRequires在clang-format 15中的重命名IndentWidth: 8IndentWrappedFunctionNames: false # 缩进换行后的函数名# InsertBraces: false # 在C++的控制语句后插入大括号，除非这些控制语句是在宏定义或者预处理指令里，clang-format 15InsertTrailingCommas: None # 在数组或对象尾部插入‘,’，仅对JavaScript有效，插入‘,’与BinPackArguments冲突，不能同时启用，clang-format 11JavaImportGroups: ['com', 'org'] # Java导入分组，clang-format 8JavaScriptQuotes: Leave # JavaScript引号风格，保留原样JavaScriptWrapImports: true # JavaScript import折行KeepEmptyLinesAtTheStartOfBlocks: false # 保留块开头处的空行LambdaBodyIndentation: Signature # lambda定义体缩进，clang-format 13# Language: None # 在这里定义本节支持的语言MacroBlockBegin: '' # 表示宏块开始的正则表达式MacroBlockEnd: '' # 表示宏块结束的正则表达式MaxEmptyLinesToKeep: 1 # 可保留的最大空行NamespaceIndentation: None # 相对namespace的缩进NamespaceMacros: # 视为namespace的宏，clang-format 9 - NAMESPACEObjCBinPackProtocolList: Auto # Objective-C相关，clang-format 7ObjCBlockIndentWidth: 8ObjCBreakBeforeNestedBlockParam: true # clang-format 11ObjCSpaceAfterProperty: trueObjCSpaceBeforeProtocolList: truePPIndentWidth: -1 # 预处理器指令缩进宽度，设为-1（默认值）时，IndentWidth用于预处理器指令，clang-format 13PackConstructorInitializers: CurrentLine # 构造器的初始化列表合并方式，clang-format 14# Taken from git's rulesPenaltyBreakAssignment: 10 # clang-format 5PenaltyBreakBeforeFirstCallParameter: 30PenaltyBreakComment: 10PenaltyBreakFirstLessLess: 0PenaltyBreakOpenParenthesis: 0PenaltyBreakString: 10PenaltyBreakTemplateDeclaration: 10 # clang-format 7PenaltyExcessCharacter: 100PenaltyIndentedWhitespace: 0PenaltyReturnTypeOnItsOwnLine: 60PointerAlignment: Right # 指针和引用的对齐风格：*和&amp;是靠近变量名还是靠近类型名RawStringFormats: - Language: Cpp Delimiters: - cc - CC - cpp - Cpp - CPP - 'c++' - 'C++' CanonicalDelimiter: '' BasedOnStyle: google - Language: TextProto Delimiters: - pb - PB - proto - PROTO EnclosingFunctions: - EqualsProto - EquivToProto - PARSE_PARTIAL_TEXT_PROTO - PARSE_TEST_PROTO - PARSE_TEXT_PROTO - ParseTextOrDie - ParseTextProtoOrDie - ParseTestProto - ParsePartialTestProto CanonicalDelimiter: pb BasedOnStyle: googleQualifierAlignment: Custom # 如何排列const/volatile之类的限定符，clang-format 14QualifierOrder: ['restrict', 'static', 'const', 'constexpr', 'inline', 'volatile' , 'type'] # 限定符的排列顺序，clang-format 14ReferenceAlignment: Right # 引用的对齐方式，如不定义，使用PointerAlignment的值，clang-format 13ReflowComments: false # 是否重排注释RemoveBracesLLVM: false # 根据LLVM编码风格移除C++控制语句中的非必需的大括号，clang-format 14# RequiresClausePosition: WithPreceding # template中，requires子句的位置，clang-format 15SeparateDefinitionBlocks: Always # 插入空行分离class、struct、enum、function等定义块，clang-format 14ShortNamespaceLines: 1 # 多少行以内的namespace块被认为是短的，clang-format 13SortIncludes: false # 是否排序includeSortJavaStaticImport: Before # 排序Java静态导入，clang-format 12SortUsingDeclarations: false # 是否排序using，clang-format 5SpaceAfterCStyleCast: false # C风格的类型转换后是否加空格SpaceAfterLogicalNot: false # 逻辑非后是否加空格，clang-format 9SpaceAfterTemplateKeyword: true # template关键词后是否加空格SpaceAroundPointerQualifiers: Default # 环绕指针限定符的空格，clang-format 12SpaceBeforeAssignmentOperators: true # 赋值运算符前是否加空格SpaceBeforeCaseColon: false # 在case语句的:前插入空格，clang-format 12SpaceBeforeCpp11BracedList: true # C++11的大括号内值列表前是否加空格，clang-format 7SpaceBeforeCtorInitializerColon: true # 构造器初始化列表的:前面是否加空格，clang-format 7SpaceBeforeInheritanceColon: true # 在定义继承的:前是否加空格，clang-format 7SpaceBeforeParens: Custom # 开括号前何时应加空格SpaceBeforeParensOptions: # 自定义&#123;前的空格 AfterControlStatements: true AfterForeachMacros: false AfterFunctionDeclarationName: false AfterFunctionDefinitionName: false AfterIfMacros: false AfterOverloadedOperator: false # AfterRequiresInClause: true # clang-format 15 # AfterRequiresInExpression: false # clang-format 15 BeforeNonEmptyParentheses: falseSpaceBeforeRangeBasedForLoopColon: true # 范围for语句里面的:前是否加空格，clang-format 7SpaceBeforeSquareBrackets: false # []前是否加空格，不影响lambda表达式，影响数组定义，clang-format 10SpaceInEmptyBlock: false # 空的块里面是否加空格，clang-format 10SpaceInEmptyParentheses: false # 空的()里面是否允许空格SpacesBeforeTrailingComments: 1 # 行尾注释符前的空格数SpacesInAngles: Never # &lt;&gt;里面是否添加空格SpacesInCStyleCastParentheses: false # C风格的强制转换括号里是否添加空格SpacesInConditionalStatement: false # 条件语句里面条件两侧是否添加空格：如if ( a )SpacesInContainerLiterals: false # 容器字面量（Objective C和JavaScript的数组及字典字面量）是否添加空格SpacesInLineCommentPrefix: Minimum: 1 Maximum: 1SpacesInParentheses: false # ()里面的左、右边界是否添加空格SpacesInSquareBrackets: false # []里面的左、右边界是否添加空格Standard: c++03 # 以此标准解析和格式化C++结构体StatementAttributeLikeMacros: - Q_EMITStatementMacros: - Q_UNUSED - QT_REQUIRE_VERSIONTabWidth: 8TypenameMacros: ['STACK_OF', 'LIST'] # 视为类型声明，而非函数调用的宏，clang-format 9UseCRLF: false # 是否使用“\\r\\n”UseTab: AlwaysWhitespaceSensitiveMacros: - STRINGIZE - PP_STRINGIZE - BOOST_PP_STRINGIZE - NS_SWIFT_NAME - CF_SWIFT_NAME... 继承配置 每个配置项都核对一遍，总是费时费力的，好在ClangFormat允许我们基于预定义的编码风格，仅修改自己需要的部分即可，这是设置BasedOnStyle配置项的值为预定义的编码风格名字来实现的。以下是一个类似于Linux kernel coding style的编码风格配置： 123456BasedOnStyle: LLVMIndentWidth: 8UseTab: AlwaysBreakBeforeBraces: LinuxAllowShortIfStatementsOnASingleLine: falseIndentCaseLabels: false 另一种继承方式，是在.clang-format文件中将BasedOnStyle的值设置为InheritParentConfig，此时，将向父目录逐级查找一个最靠近当前目录的.clang-format文件作为基础，再叠加本文件的配置。如果任一级父目录都找不到.clang-format文件，则使用–fallback-style选项指定的编码风格为基础，若未设置–fallback-style选项，默认为LLVM预定义编码风格。一种常见的情况是：为了最小化提交代码时的差异，往往是不开AlignConsecutiveAssignments（对齐连续赋值时的赋值符）、AlignConsecutiveDeclarations（对齐连续定义的变量名）、ReflowComments（重排注释）、SortIncludes（重排#include指令）这些选项的。但是在特定的子模块里面，却可能希望打开这些来获得一个更好的阅读效果，为此，就可以在子模块的.clang-format里面编写如下内容： 12345BasedOnStyle: InheritParentConfigAlignConsecutiveAssignments: AcrossCommentsAlignConsecutiveDeclarations: AcrossCommentsReflowComments: trueSortIncludes: CaseSensitive 对局部代码禁止格式化 工具并不是万能的，在有些时候，我们已经手工整理好一些内容，而不希望clang-format去改变它时，可以将它放在注释// clang-format off和// clang-format on之间，或者/* clang-format off */和/* clang-format on */之间。例如： 12345int formatted_code;// clang-format off void unformatted_code ;// clang-format onvoid formatted_code_again; 参考资料 ClangFormat Clang-Format Style Options ClangFormat参考","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"},{"name":"代码质量","slug":"代码质量","permalink":"https://www.sfysoft.com/tags/代码质量/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"ClangFormat参考","slug":"ClangFormat-Reference","date":"2022-05-09T14:43:55.000Z","updated":"2023-09-14T05:55:05.343Z","comments":true,"path":"2022/05/09/ClangFormat-Reference/","link":"","permalink":"https://www.sfysoft.com/2022/05/09/ClangFormat-Reference/","excerpt":"","text":"概述 ClangFormat是一组基于LibFormat的工具，它根据风格选项（Style Options）来格式化C系语言源代码，如C/C++/Java/JavaScript/Objective-C/C#语言的源代码，也可以格式化JSON/Protobuf这样描述数据的代码。ClangFormat可以以独立的或编辑器集成的方式工作。独立的程序名为clang-format。 工具下载与安装 对于Debian类的系统，直接使用apt install clang-format即可安装clang-format，但这样安装的版本可能较旧，而clang-format仍在不断地更新中，新的版本可能增加了更多的格式化特性，推荐到LLVM Github Release页面下载最新的clang+llvm包。例如，对于LLVM 14.0.0版本，PC Linux可以下载clang+llvm-14.0.0-x86_64-linux-gnu-ubuntu-18.04.tar.xz，64位Windows下载LLVM-14.0.0-win64.exe。 一般来讲，Linux系统里自带的clang-format包，其安装目录是在/usr下，我们下载的包可以解压到/usr/local下，即压缩包里面的bin、include、lib、libexec、share等目录是放在/usr/local下面的，在PATH环境变量的设置中，默认/usr/local/bin在/usr/bin之前，如此操作，不破坏系统自带的clang-format包，但会使用用户自己安装的clang-format。 下面的说明假设INSTALL_DIR代表了/usr/local，clang-format程序在/usr/local/bin下面。 独立工具clang-format clang-format的基本用法是：clang-format [选项] [文件列表]，clang-format将对文件列表中列出的文件进行格式化，若没有提供文件列表，则从标准输入读入内容进行格式化。若提供了文件列表及-i选项，则clang-format格式的结果直接写入文件，否则，结果写到标准输出。使用clang-format --help可以查看支持的选项。 clang-format选项说明 以下选项以clang-format 14.0.0为基准。 格式化选项 123456789101112131415161718192021222324252627282930313233343536373839404142434445--Wclang-format-violations - 警告需要更改个别格式，仅与--dry-run或-n同时使用--Werror - 将格式化时的警告视为错误--Wno-clang-format-violations - 不警告需要更改个别格式，仅与--dry-run或-n同时使用--Wno-error=&lt;value&gt; - 对value指定的警告类型不视为错误，当前value仅支持设置为unknown =unknown - 对于未知的格式化选项，仅仅警告并继续格式化。不同版本的clang-format，支持的格式化选项可能不同， 因此这选项在实际使用时非常有用，否则，在使用低版本的clang-format处理较高版本才支持的选项时， 可能持续产生错误而不进行格式化。但是它也可能因为某些选项不支持而产生一些很奇怪的结果。--assume-filename=&lt;string&gt; - 覆盖用于探测语言的文件名，典型地，当从标准输入读入时，clang-format可以用这个文件名来确定是何种编程语言--cursor=&lt;uint&gt; - 光标位置，主要用于编辑器集成时调用clang-format--dry-run - 不产生实际的格式化修改，仅打印警告或错误信息--dump-config - 提取配置选项到标准输出并退出，通常与-style选项合用--fcolor-diagnostics - 若设置，在支持颜色控制的终端上，以不同颜色打印诊断信息--fallback-style=&lt;string&gt; - 指定一个预定义的编码风格名，当clang-format以-style=file选项调用，但却找不到.clang-format文件时，回退到使用此编码风格 若使用-fallback-style=none，则跳过格式化--ferror-limit=&lt;uint&gt; - 设置在停止前可报告的最大错误数，仅和--dry-run或-n一起使用，0意味着无限制--files=&lt;string&gt; - 提供一组文件列表以运行clang-format。string指示了一个文件名，其内容是一组要被格式化的文件的路径，一行指定一个文件路径--fno-color-diagnostics - 若设置，在支持颜色控制的终端上，不以不同颜色打印诊断信息-i - 直接编辑要格式化的文件--length=&lt;uint&gt; - 格式化length指定长度的范围，length的单位为字节。 通过指定多对--offset和--length选项，可以格式化多个范围。 若仅指定了一个--offset而无--length选项，clang-format将格式化到文件结尾。 此选项仅可用于只有一个输入文件时。--lines=&lt;string&gt; - &lt;起始行&gt;:&lt;结束行&gt; - 格式化指定范围的行，行号从1开始。 可以使用多个--lines参数来指定多组范围。 此选项不与--offset和--length同时使用。 此选项仅可用于只有一个输入文件时。-n - --dry-run的别名。--offset=&lt;uint&gt; - 格式化范围从offset指定的字节处起。 通过指定多对--offset和--length选项，可以格式化多个范围。 此选项仅可用于只有一个输入文件时。--output-replacements-xml - 输出替换操作为XML--qualifier-alignment=&lt;string&gt; - 若设置，覆盖由QualifierAlignment选项指定的限定符（const、inline、static、constexpr、volatile、restrict、type）对齐风格。 更多内容参考[Clang-Format Style Options](https://clang.llvm.org/docs/ClangFormatStyleOptions.html)。--sort-includes - 若设置，覆盖由SortIncludes选项指定的include排序风格。 更多内容参考[Clang-Format Style Options](https://clang.llvm.org/docs/ClangFormatStyleOptions.html)。--style=&lt;string&gt; - 编码风格，当前支持的值包括: LLVM，GNU，Google，Chromium，Microsoft，Mozilla，WebKit。 使用--style=file则从源文件所在目录起，逐级往父级目录查找并加载.clang-format文件中定义的编码风格配置； 若要格式化的内容来自标准输入，则从当前目录加载.clang-format文件。 使用--style=file:&lt;path/to/styleFile&gt;来显式指定所使用的编码风格文件，此时用的是&lt;path/to/styleFile&gt;而非.clang-format来指定编码风格。 &lt;path/to/styleFile&gt;可以是绝对路径，也可以是相对于工作目录的 使用--style=\"&#123;key: value, ...&#125;\"来指定特定的编码风格，这样指定的编码风格会应用到所有的输入文件，例如： --style=\"&#123;BasedOnStyle: llvm, IndentWidth: 8&#125;\" 从.clang-format加载编码风格是默认行为。--verbose - 若设置，在每个格式化输出前显示所处理文件的路径 通用选项 1234567--help - 显示有效的选项（--help-hidden可以查看更多）--help-hidden - 显示所有有效的选项--help-list - 显示有效选项的列表（--help-list-hidden可以查看更多）--help-list-hidden - 显示所有有效选项的列表--print-all-options - 在解析完命令行后，显示所有选项的值。可能没什么用--print-options - 在解析完命令行后，显示所有非默认选项。可能没什么用--version - 显示程序的版本 配置编码风格 .clang-format文件使用YAML格式来配置各种编码风格： 1234key1: value1key2: value2# A comment.... 配置文件由多个节组成，并可以用不同的Language:参数来说明，这一节的配置应用于何种语言。第一节没有语言设置，它设置用于所有语言的默认编码风格。特定语言节里的配置将覆盖默认节的同名设置。 当clang-format格式化一个文件时，会使用文件名来自动探测语言，当格式化标准输入，或者文件并没有一个扩展名时，--assume-filename=选项可以覆盖clang-format用来探测语言的文件名。 以下是一个支持多语言的配置示例： 12345678910111213141516171819202122---# 默认使用LLVM的编码风格，但是使用4列的缩进宽度BasedOnStyle: LLVMIndentWidth: 4---Language: Cpp# Force pointers to the type for C++.DerivePointerAlignment: falsePointerAlignment: Left---Language: JavaScript# Use 100 columns for JS.ColumnLimit: 100---Language: Proto# Don't format .proto files.DisableFormat: true---Language: CSharp# Use 100 columns for C#.ColumnLimit: 100... 当我们要开始编写一个自己的配置时，最简单的方式就是从预定义的编码风格里生成一个包含所有配置项的.clang-format文件，然后再根据需要编辑它。 1clang-format --style=LLVM --dump-config &gt; .clang-format 最新版本支持的完整编码风格可以参考Clang-Format Style Options。 对局部代码禁止格式化 工具并不是万能，当有些时候，我们已经手工整理好一些内容，而不希望clang-format去改变它时，可以将它放在注释// clang-format off和// clang-format on之间，或者/* clang-format off */和/* clang-format on */之间。例如： 12345int formatted_code;// clang-format off void unformatted_code ;// clang-format onvoid formatted_code_again; 编辑器集成 vim集成 vim可配置为调用clang-format来格式化当前缓冲区，也可以仅格式化选定区域，要使用此功能，添加如下内容到.vimrc来调用&lt;INSTALL_DIR&gt;/share/clang/clang-format.py脚本： 1234567if has('python') map &lt;C-I&gt; :pyf /usr/local/share/clang/clang-format.py&lt;cr&gt; imap &lt;C-I&gt; &lt;c-o&gt;:pyf /usr/local/share/clang/clang-format.py&lt;cr&gt;elseif has('python3') map &lt;C-I&gt; :py3f /usr/local/share/clang/clang-format.py&lt;cr&gt; imap &lt;C-I&gt; &lt;c-o&gt;:py3f /usr/local/share/clang/clang-format.py&lt;cr&gt;endif map行配置了NORMAL和VISUAL模式，imap行配置了INSERT模式，C-I表示Ctrl+i，如此，我们就绑定了Ctrl+i作为快捷键来执行clang-format.py。在NORMAL和INSERT模式时，按下Ctrl+i会格式化当前行，而在VISUAL模式时，按下Ctrl+i会格式化选定区域。被格式化的行或选定区域可能会扩展到一个更大的词法分析范围。 格式化操作对当前缓冲区有效，它并不创建也不保存任何文件，如果要撤消格式化，使用u命令撤消即可。 上述配置，要求vim带有python的支持。可以通过vim --verison命令来查看，你所用的vim版本包含了哪些特性，如果输出中，python3前面有+号，表明支持Python 3，py3f命令是有效的，如果python前面有+号，则支持Python 2，pyf命令是有效的，若均不支持，则上述配置无效。 还有一个选择是保存文件时，格式化修改过的部分，只要把如下内容加到.vimrc里面就可以在保存扩展名为.h、.c、.cc、.cpp的文件时自动格式化修改过的行： 12345678910function! FormatOnSave() let l:formatdiff = 1 if has('python') pyf /usr/local/share/clang/clang-format.py elseif has('python3') py3f /usr/local/share/clang/clang-format.py endifendfunctionautocmd BufWritePre *.h,*.c,*.cc,*.cpp call FormatOnSave() CLion集成 clang-format已经作为一个可选的代码格式化器集成进CLion。若在打开的项目根目录下存在.clang-format文件，CLion会自动使用.clang-format文件中定义的代码样式，包括缩进、自动完成、代码生成、重构。此时，打开CLion-&gt;设置-&gt;编辑器-&gt;代码样式时，会提示“设置可能被 ClangFormat 重写”。若不需要使用clang-format，可在此提示旁边点击“禁用”。 Visual Studio集成 Visual Studio自2017 15.7 Preview 1版本起，已经内置了clang-format的支持，若是早期的版本，可从LLVM Snapshot Builds下载相应的扩展。默认绑定的快捷键是Ctrl+R，Ctrl+F。 Visual Studio Code集成 可从Visual Studio Marketplace下载最新的扩展。默认绑定的快捷键是Alt+Shift+F。 其它编辑器集成 ClangFormat还提供Emacs、BBEdit、Sublime等编辑器的插件，具体可以参考&lt;INSTALL_DIR&gt;/share/clang/目录下的文件。 应用于patch的格式化脚本 INSTALL_DIR/share/clang/clang-format-diff.py解析合并差异（unified diff）的输出，并使用clang-format格式化所有包含的行。 所以，格式化最新一个git提交的所有行，如下操作即可： 1git diff -U0 --no-color HEAD^ | clang-format-diff.py -i -p1 对于Mercurial/hg，则为如下命令： 1hg diff -U0 --color=never | clang-format-diff.py -i -p1 对于SVN，则为如下命令： 1svn diff --diff-cmd=diff -x -U0 | clang-format-diff.py -i 选项-U0是用来创建无上下文行的差异，否则脚本会把上下文行也格式化了。 这些命令使用了差异输出中的文件路径，所以，仅能在仓库的根目录下工作。 参考资料 ClangFormat LLVM Snapshot Builds Clang-Format Style Options","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"},{"name":"代码质量","slug":"代码质量","permalink":"https://www.sfysoft.com/tags/代码质量/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"OpenSSL使用Ed25519算法签名","slug":"Sign-with-Ed25519-by-OpenSSL","date":"2021-05-31T08:45:37.000Z","updated":"2023-09-14T05:55:05.355Z","comments":true,"path":"2021/05/31/Sign-with-Ed25519-by-OpenSSL/","link":"","permalink":"https://www.sfysoft.com/2021/05/31/Sign-with-Ed25519-by-OpenSSL/","excerpt":"","text":"Ed25519是一个公钥数字签名系统，以高性能及高安全性著称，其介绍可以参见这里，本文只描述如何利用OpenSSL来支持这一方法的签名和验证。所使用的环境包括Ubuntu 20.04 x64、OpenSSL 3.0.0 Alpha 13。 OpenSSL编译 目前，Ubuntu 20.04 x64系统上自带的OpenSSL版本为1.1.1f，而Ed25519算法，在OpenSSL 3.0.0以后才得到支持，因此，需要自己编译源码安装新版本，已经验证的OpenSSL版本，对应于其git源码tag openssl-3.0.0-alpha13。编译安装过程如下： 12345678910111213$ git clone https://github.com/openssl/openssl.git$ cd openssl$ git checkout -b v3.0.0-alpha13 openssl-3.0.0-alpha13# 若要生成静态链接的可执行文件，使用./Configure -static$ ./Configure$ make# 默认安装到/usr/local/[bin|include|lib|share|ssl]$ sudo make install# 清除Shell先前缓冲执行文件路径$ hash -r# 验证OpenSSL版本，正常应该是输出OpenSSL 3.0.0-alpha13 11 Mar 2021这样的$ openssl versionOpenSSL 3.0.0-alpha13 11 Mar 2021 (Library: OpenSSL 3.0.0-alpha13 11 Mar 2021) 使用方法 生成私钥 1$ openssl genpkey -algorithm Ed25519 -out private.pem 生成公钥 1$ openssl pkey -in private.pem -pubout -out public.pem 以私钥签名/bin/ls 1$ openssl pkeyutl -sign -inkey private.pem -out sig.dat -rawin -in /bin/ls 以公钥验证/bin/ls 12$ openssl pkeyutl -verify -pubin -inkey public.pem -rawin -in /bin/ls -sigfile sig.datSignature Verified Successfully","categories":[{"name":"信息安全","slug":"信息安全","permalink":"https://www.sfysoft.com/categories/信息安全/"}],"tags":[{"name":"OpenSSL","slug":"OpenSSL","permalink":"https://www.sfysoft.com/tags/OpenSSL/"}],"keywords":[{"name":"信息安全","slug":"信息安全","permalink":"https://www.sfysoft.com/categories/信息安全/"}]},{"title":"如何给嵌入式Linux构建一个支持多特性的perf","slug":"How-to-build-perf","date":"2021-05-26T10:58:26.000Z","updated":"2023-09-14T05:55:05.351Z","comments":true,"path":"2021/05/26/How-to-build-perf/","link":"","permalink":"https://www.sfysoft.com/2021/05/26/How-to-build-perf/","excerpt":"","text":"本文涉及环境为Ubuntu 20.04 x86_64、Ubuntu 20.04 ARM64、Linux Kernel源码Tag v5.9.11。 Perf工具对于Linux性能分析非常有用，在PC的Linux发行版上，只需要使用相应系统的包管理命令安装即可，例如，在Ubuntu系统上，直接使用sudo apt-get install -y linux-tools-common linux-tools-generic命令安装，其中linux-tools-common提供了各种linux tools的包装器，如acpidbg、perf等，它们会在运行时引用到适合当前内核版本的工具，而linux-tools-generic是个虚拟包，指向当前发行版最新的linux tools版本，这里面包含了真正要执行的命令。 常规交叉编译方法及其问题 对于嵌入式系统，通常需要自己编译perf，perf的源码已经集成到Linux Kernel中，以ARM64位体系架构为例，常规的交叉编译方法是执行如下命令： 12345$ sudo apt-get install gcc-aarch64-linux-gnu flex libssl-dev$ cd KERNEL_SRC/tools/perf$ make ARCH=arm64 CROSS_COMPILE=aarch64-linux-gnu- V=1 VF=1 |&amp; tee build.log$ file perfperf: ELF 64-bit LSB shared object, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=eebe3fc457239da83b56a90b27b251df10160b3b, for GNU/Linux 3.7.0, with debug_info, not stripped 从上面的file命令输出可以看到这个perf程序是动态链接的，如此就要求交叉编译时引用的动态库与目标板上运行时的动态库是兼容的，省事的做法是，编译perf时的环境和构建目标系统的环境是一致的，这包括宿主机操作系统版本和工具链版本等。否则在目标板上运行时可能出现类似下面的错误： 12$ perfperf: /lib/libc.so.6: version `GLIBC_2.28' not found (required by perf) 然而，make的输出可能还给出了其它信息，查看make命令最开始的输出，可以看到类似以下的内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455Auto-detecting system features:... dwarf: [ OFF ]... dwarf_getlocations: [ OFF ]... glibc: [ on ]... libbfd: [ OFF ]... libcap: [ OFF ]... libelf: [ OFF ]... libnuma: [ OFF ]... numa_num_possible_cpus: [ OFF ]... libperl: [ OFF ]... libpython: [ OFF ]... libcrypto: [ OFF ]... libunwind: [ OFF ]... libdw-dwarf-unwind: [ OFF ]... zlib: [ OFF ]... lzma: [ OFF ]... get_cpuid: [ OFF ]... bpf: [ on ]... libaio: [ on ]... libzstd: [ OFF ]... disassembler-four-args: [ OFF ]... backtrace: [ on ]... eventfd: [ on ]... fortify-source: [ on ]... sync-compare-and-swap: [ on ]... get_current_dir_name: [ on ]... gettid: [ on ]... libelf-getphdrnum: [ OFF ]... libelf-gelf_getnote: [ OFF ]... libelf-getshdrstrndx: [ OFF ]... libelf-mmap: [ OFF ]... libpython-version: [ OFF ]... libslang: [ OFF ]... libslang-include-subdir: [ OFF ]... pthread-attr-setaffinity-np: [ on ]... pthread-barrier: [ on ]... reallocarray: [ on ]... stackprotector-all: [ on ]... timerfd: [ on ]... sched_getcpu: [ on ]... sdt: [ OFF ]... setns: [ on ]... file-handle: [ on ]Makefile.config:389: No libelf found. Disables 'probe' tool, jvmti and BPF support in 'perf record'. Please install libelf-dev, libelf-devel or elfutils-libelf-develMakefile.config:556: No sys/sdt.h found, no SDT events are defined, please install systemtap-sdt-devel or systemtap-sdt-devMakefile.config:631: Disabling post unwind, no support found.Makefile.config:697: No libcrypto.h found, disables jitted code injection, please install openssl-devel or libssl-devMakefile.config:713: slang not found, disables TUI support. Please install slang-devel, libslang-dev or libslang2-devMakefile.config:759: Missing perl devel files. Disabling perl scripting support, please install perl-ExtUtils-Embed/libperl-devMakefile.config:791: No 'python-config' tool was found: disables Python support - please install python-devel/python-devMakefile.config:875: No liblzma found, disables xz kernel module decompression, please install xz-devel/liblzma-devMakefile.config:888: No libzstd found, disables trace compression, please install libzstd-dev[el] and/or set LIBZSTD_DIRMakefile.config:899: No libcap found, disables capability support, please install libcap-devel/libcap-devMakefile.config:912: No numa.h found, disables 'perf bench numa mem' benchmark, please install numactl-devel/libnuma-devel/libnuma-devMakefile.config:967: No libbabeltrace found, disables 'perf data' CTF format support, please install libbabeltrace-dev[el]/libbabeltrace-ctf-dev 以上表明，有多个库找不到，以致相应的特性得到支持，这可能导致最后使用时出现问题，例如：所捕获数据用来生成火焰图时有些函数名是unknown（这个问题详见后文参考资料）。 要生成一个能在目标系统上运行的，支持所有特性的perf版本，基本上有这些要求： 编译时与运行时内核版本一致，这个一般不难满足，直接使用构建目标系统时用到的内核源码或者使用一个相同版本号的标准内核源码即可 编译成静态链接的版本，这样就无需处理目标系统上已有的支持库是否缺失或者与编译时链接库版本不一致的问题 编译时尽可能提供所有特性需要依赖的库 这里面最难的就是提供所有特性需要依赖的静态库，手工编译源码安装一些工具的开发者可能都会有印象，支持库的依赖解决是很麻烦的，各种库的版本要匹配，对编译器的版本可能还存在依赖。正是因为这样，各大Linux发行版通过各自的方式解决了包依赖，使得安装软件非常方便。那么，在嵌入式开发中，如何处理这一情况？Buildroot及Yocto项目都提供了构建一个完整的、定制化的嵌入式Linux系统，包括了根文件系统、工具链等。然而，在perf这个实例里，Buildroot目前还缺少上述日志中列出的多个包，而Yocto至少已知构建速度很慢、学习曲线很陡峭。其它的类似项目还包括Cross Linux From Scratch，可能也会有类似的问题。 利用Ubuntu ARM64 Docker的解决方案 Ubuntu是开发人员中常用的系统，提供了非常丰富的软件包，这里面包括许多的支持库，这些库不仅有交叉编译的版本，还有静态链接的版本（包名通常是PackageName-dev-ARCH-cross），如果能够利用Ubuntu丰富的库来生成静态链接的perf，可以大大减少我们自己去生成这些依赖库的时间。 平时，我们在x86或x86_64体系架构上运行Ubuntu，虽然可以安装各种以-cross结尾的库来交叉编译，但逐一安装就很繁琐了，事实上Ubuntu如果已经支持某个包，想要自己编译安装它，是很简单的，以i2c-tools为例，大概执行以下几步就能搞定 123456# 下载源代码并打上Ubuntu特定patchapt-get source i2c-tools# 安装构建i2c-tools的依赖包sudo apt-get build-dep i2c-tools# 编译源码并生成deb包apt-get source --compile i2c-tools 当然我们平时不需要这么做，因为直接sudo apt-get install i2c-tools就能下载预编译好的包安装了。这里对我们有用的是apt-get build-dep命令可以轻而易举地帮我们解决大部分依赖问题，通过一定的配置（sudo dpkg --add-architecture arm64），还可以使用sudo apt-get build-dep -a arm64 PackageName来安装其它体系架构的依赖包。然而，Ubuntu同样提供了其它架构的版本，查看Ubuntu 21.04 Release页面，已经支持ARM、ARM64、PowerPC、System Z等多种体系架构。因此，如果我们在ARM64位版本的Ubuntu里安装相应的依赖库，并执行编译，就不存在交叉编译的问题，而是直接生成ARM64位版本。所以，现在的首要问题是能够运行一个ARM64位版本的Ubuntu系统，从头安装这样的一个系统当然很麻烦，好在我们可以使用docker技术，在x86_64位Ubuntu中，执行ARM64位版本的Ubuntu系统。在Docker Hub的arm64v8/ubuntu仓库中，已经提供了Ubuntu的多个ARM64位版本，这些容器不能直接在x86_64的Linux版本上运行，而是需要使用qemu模拟器来执行它，简单地来说，就是如下的操作： 1234567sudo apt-get install -y qemu-user-staticdocker run -it -v /usr/bin/qemu-aarch64-static:/usr/bin/qemu-aarch64-static \\ -v /home:/home \\ -v /etc/passwd:/etc/passwd \\ -v /etc/group:/etc/group \\ -v /etc/shadow:/etc/shadow \\ arm64v8/ubuntu:20.04 bash 现在我们已经获得一个Ubuntu 20.04的ARM64位容器，可以通过在容器中运行下列的命令来确认当前体系架构： 12# uname -maarch64 接下来，可以在这个容器里安装好编译linux-tools-generic的必要依赖并执行编译： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 启用sources.list中的源代码下载路径，以便apt-get build-dep可以运行sed -i \"s/# deb-src/deb-src/g\" /etc/apt/sources.listapt-get update -y# 先安装一些必要的工具，如果不需要内建jvmti引擎的支持，可不安装default-jdkapt-get install -y apt-utils bc bison dialog flex python3 python2-minimal default-jdk# 自动安装构建linux-tools-generic包的大部分工具和依赖库apt-get build-dep -y linux-tools-generic# 使用下面的命令尝试静态编译，然后从日志中再查看还缺少的库，并逐一安装# cd KERNEL_SRC/tools/perf# make V=1 VF=1 FEATURE_TESTS=all LDFLAGS=-static |&amp; tee build.log# 根据上条命令的输出提示，安装缺少的包，反复尝试此过程apt-get install -y libelf-devapt-get install -y libdw-devapt-get install -y systemtap-sdt-devapt-get install -y libssl-devapt-get install -y libslang2-devapt-get install -y libperl-devapt-get install -y python-devapt-get install -y liblzma-devapt-get install -y libzstd-devapt-get install -y libcap-devapt-get install -y libnuma-devapt-get install -y libiberty-devapt-get install -y libbabeltrace-devapt-get install -y libbabeltrace-ctf-devapt-get install -y libunwind-dev# 即使安装了相应包后，仍旧会有No libdw DWARF unwind found这种提示，此时需要调试Makefile来判断真实原因# make -n -d V=1 VF=1 FEATURE_TESTS=all LDFLAGS=-static |&amp; tee build.log# /usr/bin/make -f Makefile.perf -n -d V=1 VF=1 FEATURE_TESTS=all LDFLAGS=-static all |&amp; tee build.log# 通过上面命令的调试日志，可以看出来，是由KERNEL_SRC/tools/build/Makefile.feature来检测feature是否支持的# 再具体到Makefile.feature，又可调试feature_check_code，将之添加$(warning)函数来输出检查feature时执行的命令# 从命令的输出可以看到测试日志都在KERNEL_SRC/tools/build/feature/test-FEATURE.make.output中# 针对每一个为OFF的feature，查看这些output文件，才会知道检测失败的真实原因# 例如，从tools/build/feature/test-dwarf.make.output中看到的dwarf检测失败原因其实是/usr/bin/ld: cannot find -lbz2apt-get install -y libbz2-devapt-get install -y binutils-devapt-get install -y libglib2.0-devapt-get install -y libopencsd-devapt-get install -y libclang-9-dev clangapt-get install -y llvm-9-dev llvm llvm-9apt-get install -y libpfm4-dev# 为何最终使用下面的命令编译，查看后文问题说明make V=1 VF=1 FEATURE_TESTS=all NO_LIBBABELTRACE=1 NO_JVMTI=1 |&amp; tee shared.logrm perfmake V=1 VF=1 FEATURE_TESTS=all NO_LIBBABELTRACE=1 NO_JVMTI=1 LDFLAGS=-static |&amp; tee static.log 有些在ARM64架构上确实还不支持的，只能保留OFF了，为OFF的feature可能有： libnuma：较低版本的Ubuntu（如16.04）没有libnuma-dev库，20.04是有的 numa_num_possible_cpus：同上 get_cpuid：尽管在2019年12月13日的一个内核patch中（提交ID：df5a5f3cf24608457bb5e57297dd9f0d528be58f）已经增加了ARM64版本的get_cpuid支持，但是，Ubuntu 20.04的内核头文件及libgcc-X-dev包尚未提供支持 disassembler-four-args：较早期的binutils-dev（至少 2.26.1前）提供的disassembler函数接口不同于新版本的，导致编译出错 gettid：早期版本的libc6-dev（如2.23）可能并没有提供此函数 libslang-include-subdir：测试libslang的头文件目录布局，并不太影响功能，libslang是用于TUI的，可以不支持 reallocarray：早期版本的libc6-dev（如2.23）可能并没有提供此函数 bionic：这是Android的C库，可以不支持，如果是用于Android，可考虑安装NDK来支持 compile-[x]32：这两个都以生成32位版的perf有关，并不需要 hello：简单的测试程序，这个为OFF，通常只是因为没有对所有feature进行测试而已，如果需要测试所有的，可以给make指定FEATURE_TESTS=all，也就是make V=1 VF=1 LDFLAGS=-static FEATURE_TESTS=all gtk2/gtk2-infobar：GTK+ GUI支持，嵌入式系统一般不需要 libbabeltrace：静态链接时，链接参数指定的库不够导致编译错误，可以使用NO_LIBBABELTRACE=1禁止这一支持，以免引起编译错误，或使用下面的补丁 libopencsd：Ubuntu 20.04上的OpenCSD版本较低，为0.12.2，不满足v5.9.11版Kernel对OpenCSD 1.0.0以上的要求，如果需要可以手工下载源码编译安装 libunwind-x86：这里是编译ARM64架构的perf，自然是不支持的 libunwind-x86_64：这里是编译ARM64架构的perf，自然是不支持的 libunwind-arm：这里是编译ARM64架构的perf，自然是不支持的 libunwind-debug-frame-arm：这里是编译ARM64架构的perf，自然是不支持的 llvm：首先，使用llvm-10时编译会出错，原因是函数定义不匹配，需要将/usr/bin/llvm-config指向llvm9（rm /usr/bin/llvm-config &amp;&amp; ln -s ../lib/llvm-9/bin/llvm-config /usr/bin/llvm-config）。其次，改为llvm9后静态编译，Ubuntu 20.04没有LLVM-9.a这个静态库，若是动态链接，无此问题 clang：同上 libbpf：Ubuntu 20.04尚未提供此库，但在编译过程中，会使用内核源码中生成的tools/lib/bpf/libbpf.a libdebuginfod：Ubuntu 20.04的libelf-dev尚未提供debuginfod的支持 clang-bpf-co-re：与clang版本有关，已知clang-10是没有问题的，clang-9是有问题的 其它的feature检测，则可能是由于tools/build/feature/Makefile本身定义的规则有问题导致，通常是链接库缺少，在使用Ubuntu 20.04 ARM64版本编译v5.9.11 tag对应的版本时，至少要对内核源码做如下做如下修改，才能使相应的feature检测正确： 123456789101112131415161718192021222324252627diff --git a/tools/build/feature/Makefile b/tools/build/feature/Makefileindex 8da2556cdbfa..af8a4caff3ef 100644--- a/tools/build/feature/Makefile+++ b/tools/build/feature/Makefile@@ -137,7 +137,7 @@ $(OUTPUT)test-libopencsd.bin: DWARFLIBS := -ldw ifeq ($(findstring -static,$&#123;LDFLAGS&#125;),-static)-DWARFLIBS += -lelf -lebl -lz -llzma -lbz2+DWARFLIBS += -lelf -lebl -ldl -lz -llzma -lbz2 endif $(OUTPUT)test-dwarf.bin:diff --git a/tools/perf/Makefile.config b/tools/perf/Makefile.configindex 2d6690b30856..123df1d500ff 100644--- a/tools/perf/Makefile.config+++ b/tools/perf/Makefile.config@@ -962,6 +962,9 @@ ifndef NO_LIBBABELTRACE CFLAGS += -DHAVE_LIBBABELTRACE_SUPPORT $(LIBBABELTRACE_CFLAGS) LDFLAGS += $(LIBBABELTRACE_LDFLAGS) EXTLIBS += -lbabeltrace-ctf+ ifeq ($(findstring -static,$&#123;LDFLAGS&#125;),-static)+ EXTLIBS += -lbabeltrace -lglib-2.0 -luuid+ endif $(call detected,CONFIG_LIBBABELTRACE) else msg := $(warning No libbabeltrace found, disables 'perf data' CTF format support, please install libbabeltrace-dev[el]/libbabeltrace-ctf-dev); 在做完上述修改后，重新执行 12345$ make V=1 VF=1 FEATURE_TESTS=all NO_JVMTI=1 |&amp; tee shared.log$ rm perf$ make V=1 VF=1 FEATURE_TESTS=all NO_JVMTI=1 LDFLAGS=-static |&amp; tee static.log$ ls -lh perf-rwxr-xr-x 1 root root 38M May 26 18:49 perf 看见的将是大片的[ on ]而不再是大片的[ OFF ]，如果编译顺利完成的话，得到的就是一个较完整的静态链接版perf了，而其文件大小将远远大于未启用这些特性的版本。尽管本例中并不完全支持所有特性，但剩余的通过编译源码的方式来处理，已经不再具备很大的工作量了。同时需要注意的：这些只是在用户空间的perf程序中集成了相应的特性，具体到某些功能能不能支持，还依赖于内核版本。这也是为什么Ubuntu系统对一些Linux tools做了包装脚本的原因，包装脚本会在运行时检测当前内核版本来确定运行哪一个目录下的程序。 可能遇到的问题 编译过程中提示如下错误： 123/usr/bin/make FIXDEP=1 -f Makefile.perf /usr/bin/sh: line 0: command: -c: invalid optioncommand: usage: command [-pVv] command [arg ...] 当没有安装python2时，tools/perf/Makefile.config的$(if $(call get-executable,$(PYTHON)-config),$(PYTHON)-config,python-config)将执行出错，产生这条提示，使用apt-get install -y python2-minimal安装好python2后即可解决。 编译过程中提示如下错误： 12dangerous relocation: unsupported relocation/usr/bin/ld: BFD (GNU Binutils for Ubuntu) 2.24 internal error, aborting at ../../bfd/elfnn-aarch64.c line 4331 in elf64_aarch64_final_link_relocate 这个是binutils包的问题，2.31版本后已经解决，这就是为什么使用Ubuntu 20.04的原因，这一版本里自带的binutils是2.34版本。 编译过程中提示如下错误： 12gcc -g -Wall -fPIC -I. -I.. -I /home/oak/work/perf/tools/include -D_GNU_SOURCE -shared -static -Wl,-z,noexecstack -lunwind-aarch64 -lunwind -lunwind-aarch64 -Wl,--allow-multiple-definition -Wl,-E -fstack-protector-strong -L/usr/local/lib -L/usr/lib/aarch64-linux-gnu/perl/5.30/CORE -L/usr/lib/python2.7/config-aarch64-linux-gnu -L/usr/lib -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions -nostartfiles -o plugin_kmem.so plugin_kmem-in.o/usr/bin/ld: /usr/lib/gcc/aarch64-linux-gnu/9/../../../aarch64-linux-gnu/libc.a(malloc.o): relocation R_AARCH64_ADR_PREL_PG_HI21 against symbol `__free_hook' which may bind externally can not be used when making a shared object; recompile with -fPIC 这里的原因在于生成各个插件时，Makefile只定义了编译成共享库的方式，不单是plugin_kmem.so，其它的插件也一样，包括libperf-jvmti.so等，此时指定了-static选项，而它原本又具有-shared选项，冲突的选项导致了生成这些库失败，解决办法是先编译一次动态链接版本的，把这些共享库都给生成了，而jvmti总是会重新编译，直接使用NO_JVMTI=1禁止，然后再指定-static选项编译perf： 123make V=1 VF=1 FEATURE_TESTS=all NO_JVMTI=1 |&amp; tee shared.logrm perfmake V=1 VF=1 FEATURE_TESTS=all NO_JVMTI=1 LDFLAGS=-static |&amp; tee static.log 执行过程中提示如下错误： 123456$ perf record -F 99 -p 1913 -g -- sleep 5(process:9417): GLib-CRITICAL **: 05:32:39.141: g_hash_table_insert_internal: assertion 'hash_table != NULL' failed(process:9417): GLib-CRITICAL **: 05:32:39.141: g_hash_table_lookup: assertion 'hash_table != NULL' failed(process:9417): GLib-CRITICAL **: 05:32:39.141: g_hash_table_insert_internal: assertion 'hash_table != NULL' failed(process:9417): GLib-CRITICAL **: 05:32:39.141: g_hash_table_lookup: assertion 'hash_table != NULL' failed(process:9417): GLib-CRITICAL **: 05:32:39.141: g_hash_table_insert_internal: assertion 'hash_table != NULL' failed 如果出现这个错误，则说明系统安装的libglib2.0-dev有问题，libglib2.0-dev是GTK的库，简单的办法是不使用这个库，但是，如此一来，Ubuntu 20.04 ARM64版本上编译v5.9.11时需要禁止libbabeltrace，因为系统安装的libbabeltrace使用了libglib2.0-dev中定义的函数，可用的编译命令如下： 123make V=1 VF=1 FEATURE_TESTS=all NO_LIBBABELTRACE=1 NO_JVMTI=1 |&amp; tee shared.logrm perfmake V=1 VF=1 FEATURE_TESTS=all NO_LIBBABELTRACE=1 NO_JVMTI=1 LDFLAGS=-static |&amp; tee static.log 参考资料 BFD (GNU Binutils for Debian) 2.31.1 internal error 如何读懂火焰图 perf生成火焰图使用简记 babeltrace project 使用 perf 进行性能分析时如何获取准确的调用栈","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"Ubuntu上使用MTP传输文件","slug":"Ubuntu-Use-MTP","date":"2021-04-23T10:41:18.000Z","updated":"2023-09-14T05:55:05.359Z","comments":true,"path":"2021/04/23/Ubuntu-Use-MTP/","link":"","permalink":"https://www.sfysoft.com/2021/04/23/Ubuntu-Use-MTP/","excerpt":"","text":"MTP是什么 媒体传输协议是一个基于图片传输协议（PTP，Picture Transfer Protocol）的自定义扩展协议。媒体传输协议（即通常所说的MTP，英语：Media Transfer Protocol，缩写：MTP）是“Windows Media”框架的一部分，与Windows Media Player密切相关，该协议允许用户在移动设备上线性访问媒体文件。不同的应用系统需要下载不同的媒体软件包才能够支持MTP的执行。 这里主要是探讨一下利用它在PC和Android设备间传输文件。 在Ubuntu上如何通过MTP传输文件 至少在Android 5.1以后，MTP、PTP与仅限充电功能，基本上是各种Android手机标配的USB功能，其中，PTP仅能传输照片，如果要传输其它文件，通常要使用MTP。在Windows 7以后，MTP已经被Windows系统默认支持，Android手机连接到Windows系统上直接可用。而Ubuntu则经历了好几种情况： 在14.04上，通过gmtp、jmtpfs或mtpfs提供支持 在16.04上，通过gmtp、go-mtpfs、jmtpfs或mtpfs提供支持 在18.04上，通过gmtp、go-mtpfs、jmtpfs提供支持 在20.04上，通过gmtp、go-mtpfs、jmtpfs、android-file-transfer提供支持 本文是基于20.04的android-file-transfer来说明的，尽管这个软件在以前的Ubuntu发行版上并没有包含在Ubuntu官方源中，但可以通过这一软件的官方网站下载到。 安装android-file-transfer 1sudo apt install android-file-transfer 使用android-file-transfer 将Android设备连接到安装有Ubuntu 20.04的PC上，并在设备上将USB功能切换为传输文件模式。然后在Ubuntu的终端里面执行： 1sudo aft-mtp-cli 程序首先会提示当前选择了哪个存储，这是相对于设备同时存在内置存储和SD卡来说的，但如果同时插入多个不同的设备，则只能使用其中一个。接下来，会输出程序版本和设备信息后进入到交互提示符，在提示符里输入help可以看到所有的命令，常用的有： storage-list：列出当前有哪些MTP存储设备 storage &lt;设备名&gt;：切换到指定的MTP存储设备，设备名是storage-list列出的每一行的最后一个字段 ls [MTP path]：列出MTP存储设备当前所在路径或指定路径下的文件 cd &lt;MTP path&gt;：切换到MTP存储设备中指定路径 pwd：输出MTP存储设备当前所在路径 put &lt;PC file&gt; [MTP path]：从PC上复制一个文件到MTP存储设备当前路径或指定路径，注意：不会把文件路径名中的~解释为HOME目录，这里&lt;PC file&gt;和[MTP path]都可以使用绝对或相对路径 get &lt;MTP file&gt; &lt;PC path&gt;：从MTP存储设备复制一个文件到PC上，路径的用法同put exit：退出程序，quit命令也是一样的效果 有时候，只是想简单传输个文件，并不想进入到交互模式去执行这么一堆操作，这也是可以做到的，通过给aft-mtp-cli指定一个命令字符串就行了，示例： 1sudo aft-mtp-cli \"put work/app-debug.apk /Download/demo.apk\" 上述命令将PC上的work/app-debug.apk复制到MTP存储设备，路径为/Download，并重命名为demo.apk了。 甚至，可以将命令列表写在一个文件中，然后通过-b -f来指定此文件以进行批量执行，例如，文件cmds.txt包含如下内容： 12put work/app-debug.apk /Download/demo.apkls /Download/ 那么，aft-mtp-cli -b -f cmds.txt将先把PC上的work/app-debug.apk上传到MTP存储设备的/Download目录下，命名为demo.apk后，再列出MTP存储设备的/Download目录。 注意事项 在上面的操作中，每一条命令都添加了sudo前缀，这主要是由于系统限制了普通用户对USB设备的访问，为了方便起见，可以添加相应的udev规则，按如下步骤操作即可： 安装适用于 Android 设备并由社区维护的默认udev规则 sudo apt install android-sdk-platform-tools-common 查看你所使用设备的厂商ID和产品ID并记下 12$ lsusbBus 001 Device 006: ID 19d2:ffcf ZTE WCDMA Technologies MSM Android 编辑/lib/udev/rules.d/51-android.rules，并复制其中一条只匹配厂商ID的，将其厂商改掉即可，最好不要使用带产品ID，因为有时候可能匹配不上，据说是因为大小写区别导致，未经证实。示例如下： 1SUBSYSTEM==&quot;usb&quot;, ATTR&#123;idVendor&#125;==&quot;19d2&quot;, ENV&#123;adb_user&#125;=&quot;yes&quot; 重启udev 1sudo systemctl restart udev 然后就可以直接使用aft-mtp-cli而无需加sudo前缀了。 android-file-transfer提供了一个简单的UI，如果要使用图形界面，直接使用安装时生成的桌面图标或运行android-file-transfer。 参考资料 百度百科-媒体传输协议 Android开发者文档-针对开发设置设备 android-file-transfer FAQ","categories":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.sfysoft.com/tags/Ubuntu/"}],"keywords":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}]},{"title":"使用Android Studio的那些问题与解决办法","slug":"AS-Issues-and-Solution","date":"2021-04-06T11:41:05.000Z","updated":"2023-09-14T05:55:05.331Z","comments":true,"path":"2021/04/06/AS-Issues-and-Solution/","link":"","permalink":"https://www.sfysoft.com/2021/04/06/AS-Issues-and-Solution/","excerpt":"","text":"在使用Android Studio的过程中，不免会遇到些莫名其妙的问题，这些问题的产生，可能是由于Android Studio本身的版本兼容性，也可能是使用的Gradle构建工具的兼容性，或者国内网络环境的因素等。本文收集了一些使用Android Studio过程中遇到的问题及相应的解决办法，所涉及的环境为Windows 10 1909 x64和Android Studio 4.1.3 x64。 解决问题的一般方法 由于遇到的问题多种多样，有些未必能搜索到现存的解决办法，因此，最重要的还是能自己分析问题并找到解决方案，一般来讲，Android Studio的Event Log窗口和Build Output窗口都已经提示了一些失败的线索，根据这些信息来分析，往往能一步步找到解决办法。如下图： 通过中间窗口上面显示的日志，及下拉后看到的如下日志： 12Caused by: java.lang.NullPointerException at com.android.build.gradle.internal.ndk.NdkHandler.getPlatformVersion(NdkHandler.java:121) 就能判断是NDK相关的问题，此时首先应确认相应的路径下NDK有没有安装，若没有安装，需要通过File-&gt;Settings-&gt;System Settings-&gt;Android SDK设置好Android SDK Location并安装好NDK。若在安装后NDK后重新执行Sync（File-&gt;Sync Project with Gradle files），仍提示有错误，则可进一步根据提示将错误关键信息叠加Android Studio版本搜索或参考Gradle及Android Studio的文档。此例中，搜索关键词可以是“NDK is missing a “platforms” directory Android Studio 4.1.3”。 下面是各个具体问题的描述和解决办法。 构建时提示“NDK is missing a “platforms” directory” 问题原因 一些新版本的NDK下面已经没有了platforms目录，而项目使用的Gradle插件版本（顶层build.gradle文件中dependencies块指定的classpath 'com.android.tools.build:gradle:X.Y.Z'）可能并不能处理此情况。 解决办法 首先确定使用哪一个Gradle插件版本，一般选择相应Android Studio版本对应的最新Gradle插件版本，因此在顶层的build.gradle中，将dependencies块中指定的gradle配置变更如下： classpath 'com.android.tools.build:gradle:4.1.3' 此后，根据Android Studio提示安装新的Gradle版本后，重新Sync项目，仍会有相同的提示，可见新版本的Gradle插件也同样存在问题。由于某些旧的NDK版本存在platforms目录，因此规避此问题的办法，是卸载较新版本的NDK，安装回旧版本的NDK，通过File-&gt;Settings-&gt;System Settings-&gt;Android SDK，选中下图标记的复选框，可以切换所安装软件的版本，若已知现存可用的版本，直接选中取消其它安装即可，否则只需挨个尝试，并查看安装完成后相应的ndk目录下有没有platforms文件夹。 如上图安装了适当版本的NDK后，接下来是配置使用此NDK版本，尽管按照Android Gradle 插件版本说明，官方建议在模块的build.gradle中以ndkPath来指定本地NDK路径，但由于模块的build.gradle通常会提交到版本库，而不同开发者的本地NDK路径可能有所不同，因此，使用不提交到版本库的local.properties仍旧是一种不错的选择。 方式一，在模块的build.gradle（通常是app/build.gradle）中包含如下行： 123android &#123;​ ndkPath 'E:\\\\Development\\\\Android\\\\SDK\\\\ndk\\\\21.4.7075529'&#125; 方式二，在顶层目录的local.properties文件中增加如下行： 1ndk.dir=E\\:\\\\Development\\\\Android\\\\SDK\\\\ndk\\\\21.4.7075529 构建时提示“你的主机中的软件中止了一个已建立的连接” 问题描述 执行Build菜单里的Build或Clean等命令时，Build Output窗口直接提示“你的主机中的软件中止了一个已建立的连接”并失败。 问题原因 暂未深究，但此问题与Windows移动热点有关，估计当时的路由表配置有影响。 解决办法 在启动Android Studio时不要开移动热点，启动后再开。如果启动Android Studio时正打开着移动热点，则可以先关闭再打开一次移动热点，此时Android Studio无需重启。执行两种操作的任意一种后，Android Studio和移动热点功能都可以同时使用。 构建时提示“Could not install Gradle distribution from ‘xxx’” 问题原因 此问题主要出现在初次下载某个Gradle版本时。xxx是相应的下载链接，最后一部分是相应的文件名，如下载链接为https://services.gradle.org/distributions/gradle-6.5-all.zip，相应的文件为gradle-6.5-all.zip。Android Studio自动下载此文件可能较慢，在一定时间内下载不了数据就自动中止了，然后提示错误。但是点击相应的链接却可以用下载软件下载。 解决办法 方法一、关闭Android Studio，在%USERPROFILE%\\.gradle\\wrapper\\dists（通常是C:\\Users\\USERNAME\\.gradle\\wrapper\\dists）下搜索相应的文件名，如gradle-6.5-all.zip，会看到一个目录下包含有gradle-6.5-all.zip.part，进入此目录，将gradle-6.5-all.zip.part删除，并把下载软件下载到的gradle-6.5-all.zip复制到这个目录，新建一个名为gradle-6.5-all.zip.ok的空文件后重新打开Android Studio即可。 方法二、若有一个快速的代理服务器可用，也可以先编辑%USERPROFILE%\\.gradle\\gradle.properties文件，填入代理服务器地址后再打开Android Studio，此时可能很快就下载完成了。代理服务器配置示例： 1234systemProp.http.proxyHost=localhostsystemProp.http.proxyPort=10809systemProp.https.proxyHost=localhostsystemProp.https.proxyPort=10809 首次打开某项目时状态栏一直提示“Gradle sync started, X process running…” 问题原因 当首次打开一个项目时，Android Studio将解析各个build.gradle文件，下载依赖的库文件，由于默认情况下都是从jcenter和google网站下载的，在国内下载可能相当慢，点击状态栏的“X process running”可以看到具体的任务是怎样的。 解决办法 方法一、编辑项目顶层的build.gradle，将下列内容加入到buildscript块的repositories块里，替换原来的google()及jcenter()行： 12345maven &#123; url 'https://maven.aliyun.com/repository/gradle-plugin' &#125;maven &#123; url 'https://maven.aliyun.com/repository/google' &#125;maven &#123; url 'https://maven.aliyun.com/repository/public/' &#125;mavenLocal()mavenCentral() 将下列内容加入allprojects块的repositories块里，替换原来的google()及jcenter()行后重新打开Android Studio： 1234maven &#123; url 'https://maven.aliyun.com/repository/google' &#125;maven &#123; url 'https://maven.aliyun.com/repository/public/' &#125;mavenLocal()mavenCentral() 方法二、若想对所有项目生效，将下列内容加到%USERPROFILE%\\.gradle\\init.gradle文件中，之后就能从Build Output窗口中看到使用了什么仓库，被替换成了什么URL： 1234567891011121314151617181920212223242526272829303132allprojects &#123; repositories &#123; def ALIYUN_REPOSITORY_URL = 'https://maven.aliyun.com/repository/public/' def ALIYUN_GOOGLE_URL = 'https://maven.aliyun.com/repository/google/' def ALIYUN_GRADLE_PLUGIN_URL = 'https://maven.aliyun.com/repository/gradle-plugin/' all &#123; ArtifactRepository repo -&gt; if (repo instanceof MavenArtifactRepository) &#123; def url = repo.url.toString() println \"Repository: $&#123;url&#125;\" if (url.startsWith('https://dl.google.com/dl/android/maven2/')) &#123; println \"Replaced by $&#123;ALIYUN_GOOGLE_URL&#125;.\" remove repo &#125; if (url.startsWith('https://jcenter.bintray.com/')) &#123; println \"Replaced by $&#123;ALIYUN_REPOSITORY_URL&#125;.\" remove repo &#125; if (url.startsWith('https://repo1.maven.org/maven2/')) &#123; println \"Replaced by $&#123;ALIYUN_REPOSITORY_URL&#125;.\" remove repo &#125; if (url.startsWith('https://plugins.gradle.org/m2/')) &#123; println \"Replaced by $&#123;ALIYUN_GRADLE_PLUGIN_URL&#125;.\" remove repo &#125; &#125; &#125; maven &#123; url ALIYUN_GOOGLE_URL &#125; maven &#123; url ALIYUN_REPOSITORY_URL &#125; maven &#123; url ALIYUN_GRADLE_PLUGIN_URL &#125; &#125;&#125; 说明： buildscript块里定义了gradle脚本执行所需依赖，allprojects块里定义了项目生成所需依赖。 Gradle有别名的概念，可以在将Maven存储库添加到构建文件时使用它们。其中，mavenCentral()别名表示从Central Maven 2 repository获取依赖项，jcenter()别名表示从Bintray’s JCenter Maven repository获取依赖项，mavenLocal()别名表示从本地Maven存储库获取依赖项。本地仓库的位置确定，可以由环境变量或配置文件确定，具体参考Gradle文档的RepositoryHandler。仓库指向的地址在不同版本的Gradle中可能会有变化，这可以通过init.gradle中的打印观察到，如果有变化，可以同步修改init.gradle文件。 参考 Android Studio 和 Android Gradle 插件的已知问题 Android Studio 版本说明 安装及配置 NDK 和 CMake 为 Android Gradle 插件配置 NDK Android Gradle 插件版本说明 NDK is missing a “platforms” directory. while trying to build 阿里云云效 Maven 指南 Maven 仓库 Initialization Scripts Gradle User Manual","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Android Studio","slug":"Android-Studio","permalink":"https://www.sfysoft.com/tags/Android-Studio/"},{"name":"Gradle","slug":"Gradle","permalink":"https://www.sfysoft.com/tags/Gradle/"},{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"使用df命令看到的分区大小是正确的吗？","slug":"Is-fs-size-correct","date":"2020-08-11T12:43:06.000Z","updated":"2023-09-14T05:55:05.355Z","comments":true,"path":"2020/08/11/Is-fs-size-correct/","link":"","permalink":"https://www.sfysoft.com/2020/08/11/Is-fs-size-correct/","excerpt":"","text":"在使用Linux时，通常会用到df命令来查看磁盘挂载情况，那么df的输出结果可信吗？一般用户似乎不应怀疑，作者以前也从没怀疑过，直到发生了下面的这些事情。 df报告的分区大小比分区表定义的大时 在使用某芯片厂商的SDK开发产品时，检查设备上的eMMC使用情况看到有下面的情况： 123456789~# df -Th -x tmpfs -x devtmpfsFilesystem Type Size Used Avail Use% Mounted on/dev/root ext4 1.9G 622M 1.1G 36% //dev/mmcblk0p36 vfat 1.0G 0 1.0G 0% /bluetooth/dev/mmcblk0p25 vfat 95M 19M 77M 20% /firmware/dev/mmcblk0p26 ext4 12M 4.2M 7.4M 36% /dsp/dev/mmcblk0p42 ext4 28M 108K 27M 1% /persist/dev/mmcblk0p41 ext4 58M 3.1M 54M 6% /cache/dev/mmcblk0p50 ext4 3.4G 1.4G 2.0G 41% /data 一个名为bluetooth的分区竟然分配了1G的空间，那么，这里面究竟包含了什么呢？使用ls -a命令查看/bluetooth目录没有任何内容。回看厂商烧录工具使用的配置文件时，发现有这样的配置： &lt;program SECTOR_SIZE_IN_BYTES=&quot;512&quot; file_sector_offset=&quot;0&quot; filename=&quot;BTFM.bin&quot; label=&quot;bluetooth&quot; num_partition_sectors=&quot;2047&quot; partofsingleimage=&quot;false&quot; physical_partition_number=&quot;0&quot; readbackverify=&quot;false&quot; size_in_KB=&quot;1023.5&quot; sparse=&quot;false&quot; start_byte_hex=&quot;0xd8468000&quot; start_sector=&quot;7086912&quot; /&gt; 从描述上看这是个存放Bluetooth Firmware文件的分区，但定义的分区大小只有1023.5K，占用2047个扇区，这显然与df的输出不匹配，那这个分区的信息被Linux Kernel识别为怎样的？为此，做了下面的一系列试验： 12345678910111213141516171819202122~# cat /sys/class/block/mmcblk0p36/size # 查看mmcblk0p36的扇区数2048~# cat /sys/class/block/mmcblk0p36/start # 查看mmcblk0p36的起始扇区7086912~# ls -Slh /usr/lib64/ | head -n 2 # 寻找一个稍大的文件total 326M-rw-r--r-- 1 root root 56M Jul 31 2020 libQt5Bootstrap.a~# cp /usr/lib64/libQt5Bootstrap.a /bluetooth/ # 将文件复制到/bluetooth目录~# ls -lh /bluetooth/total 56M-rwxr-xr-x 1 root root 56M Aug 20 2019 libQt5Bootstrap.a~# diff /usr/lib64/libQt5Bootstrap.a /bluetooth/libQt5Bootst&gt;~# sync~# diff /usr/lib64/libQt5Bootstrap.a /bluetooth/libQt5Bootstrap.a~# sync /bluetooth/libQt5Bootstrap.async: error syncing '/bluetooth/libQt5Bootstrap.a': Input/output error~# diff /usr/lib64/libQt5Bootstrap.a /bluetooth/libQt5Bootstrap.a~# echo $?0~# reboot~# diff -q /usr/lib64/libQt5Bootstrap.a /bluetooth/libQt5Bootstrap.aFiles /usr/lib64/libQt5Bootstrap.a and /bluetooth/libQt5Bootstrap.a differ 从上面的测试中可以看到，cat命令读到的起始扇区能与配置文件中对应，但读到的扇区数多了1个扇区，猜测是扇区对齐导致。接下来通过复制大于分区表大小的文件进行试验，cp命令的输出表明复制成功，将原文件与目标文件比较，diff命令的输出表明文件内容一致，考虑到Linux的缓冲机制，文件并不一定写入了eMMC，于是又执行了一遍sync命令后再次比较，diff的输出仍旧表明文件内容一致，但给sync命令指定目标文件时，sync给出了一条错误消息，这表明不能把文件刷写到eMMC。继续比较，diff的输出仍旧表明文件内容一致，可见，文件始终是保留在缓冲区里，并没有写入到eMMC。为验证这一观点，将设备重启后再度比较，这次diff报了两个文件是不同的。 看来，mmcblk0p36分区确实只有2048个扇区，无法写入这么大的文件，那么，为什么df命令报出来是1G的，想来只有配置文件中的BTFM.bin导致的了，在Ubuntu上使用file命令查看BTFM.bin： 12$ file BTFM.binBTFM.bin: DOS/MBR boot sector, code offset 0x3c+2, OEM-ID \"MSDOS5.0\", sectors/cluster 32, root entries 512, Media descriptor 0xf8, sectors/FAT 257, sectors/track 63, heads 255, sectors 2097152 (volumes &gt; 32 MB) , reserved 0x1, serial number 0xbc614e, unlabeled, FAT (16 bit) file命令报告BTFM.bin的总扇区数有2097152个，以512字节为1扇区，2097152个扇区数恰巧是1G的空间，到此基本上可以确定是这个BTFM.bin导致的问题，当它写入设备的eMMC后，Linux从相应的分区读取了这些数据作为文件系统信息，并据此挂载，于是df等使用了/proc/self/mountinfo数据的程序都认为此分区有1G空间，但在实际写入时，Kernel却知道没有足够的扇区来存放数据，于是报了错误。 修复此问题也很简单，只需要提供一个大小匹配实际的BTFM.bin就可以了，以Kernel报的2048个扇区为准，在Ubuntu上重新生成一个用于烧录的vfat.bin文件的过程如下： 12345678910111213$ dd if=/dev/zero of=vfat.bin bs=512 count=2048 # 产生一个2048个扇区大小的文件$ mkfs.vfat -s 32 -r 512 vfat.bin # 将此文件格式化为vfat格式mkfs.fat 4.1 (2017-01-24)$ file vfat.binvfat.bin: DOS/MBR boot sector, code offset 0x3c+2, OEM-ID \"mkfs.fat\", sectors/cluster 32, root entries 512, sectors 2048 (volumes &lt;=32 MB) , Media descriptor 0xf8, sectors/FAT 1, sectors/track 32, heads 64, serial number 0x51a31e42, unlabeled, FAT (12 bit)$ mkdir vfat/$ sudo mount -t vfat -o loop vfat.bin vfat$ mkdir btfm/$ sudo mount -t vfat -o loop BTFM.bin btfm/$ #sudo cp btfm/* vfat/ # 若原bin文件包含了内容，应当复制到新的bin文件中$ sync vfat/$ sudo umount vfat # 此后vfat.bin将包含BTFM.bin的内容，并具有适当大小$ sudo umount btfm 为什么BTFM.bin是16位的FAT表，而vfat.bin是12位的FAT表，因为2048个扇区的空间太小，已经不足以使用16位的FAT表。将新生成的vfat.bin替换为原BTFM.bin并刷写到设备验证，可以看到df命令将输出除去文件系统自身信息后的正确大小，cp命令复制超出分区表空间大小的文件到分区时也将报错： 123456789101112~# df -Th -x tmpfs -x devtmpfsFilesystem Type Size Used Avail Use% Mounted on/dev/root ext4 1.9G 622M 1.1G 36% //dev/mmcblk0p36 vfat 992K 16K 976K 2% /bluetooth/dev/mmcblk0p25 vfat 95M 19M 77M 20% /firmware/dev/mmcblk0p26 ext4 12M 4.2M 7.4M 36% /dsp/dev/mmcblk0p50 ext4 3.4G 1.4G 2.0G 41% /data/dev/mmcblk0p41 ext4 58M 3.1M 54M 6% /cache/dev/mmcblk0p42 ext4 28M 108K 27M 1% /persist~# cp /usr/lib64/libQt5Bootstrap.a /bluetooth/cp: error writing '/bluetooth/libQt5Bootstrap.a': No space left on device df报告的分区大小比分区表定义的小时 在上面，已经看到了df报告的分区大小比分区表定义的大时是怎样的情况，当df报告的分区大小比分区表中小时，又将如何？正巧的是，/分区就是这样的一种情况，查看烧录工具的配置文件可以看到这样的配置： &lt;program SECTOR_SIZE_IN_BYTES=&quot;512&quot; file_sector_offset=&quot;0&quot; filename=&quot;rootfs.ext4&quot; label=&quot;system&quot; num_partition_sectors=&quot;6291455&quot; partofsingleimage=&quot;false&quot; physical_partition_number=&quot;0&quot; readbackverify=&quot;false&quot; size_in_KB=&quot;3145727.5&quot; sparse=&quot;false&quot; start_byte_hex=&quot;0xcf3a000&quot; start_sector=&quot;424400&quot; /&gt; 配置文件里定义的大小是6291455个扇区，3145727.5KB，也就是2.99G，查看sys文件系统中的信息验证： 1234# mount | grep \"/ \"/dev/mmcblk0p18 on / type ext4 (rw,relatime,data=ordered)# cat /sys/class/block/mmcblk0p18/size6291456 同样是比配置文件中定义的多了1个扇区，但df命令报告的总大小是1.9G，用掉了622M，若以2.99G为限，剩余应有（2.99G-622M）大小，那此时能复制超过1.9G的文件进去吗？试验一下就知道了： 1234~# ls -lh /media/usb1/rootfs.ext4-rwxr-xr-x 1 root root 2.1G Aug 1 2020 /media/usb1/rootfs.ext4~# cp /media/usb1/rootfs.ext4 /cp: error writing '/rootfs.ext4': No space left on device cp命令报告没有足够的空间来复制，有1G多的空间丢失了。 要修复此问题，仍旧是生成正确大小的文件系统镜像，对于ext4文件系统镜像来讲，可以用Android SDK中的make_ext4fs命令来生成的，此例中，如果要利用上分区表定义的大小，在Ubuntu上这样操作就可以了： 123$ mkdir rootfs$ sudo mount -t ext4 -o loop rootfs.ext4 rootfs$ sudo make_ext4fs -l 3145728K rootfs-raw.ext4 rootfs 上述命令使用原文件系统镜像再生成rootfs-raw.ext4文件，并指定对应到6291456个扇区的大小，产生的rootfs-raw.ext4会有3G大，若烧写工具支持Android Sparse格式，则可以使用sudo make_ext4fs -s -l 3145728K rootfs-sparse.ext4 rootfs这样的命令产生一个较小的文件。将这个文件刷回设备上验证，可以看到df命令将输出除去文件系统自身信息后的正确大小，cp命令复制2.1G大文件到/分区时正确完成： 12345678910111213141516171819~# df -Th -x tmpfs -x devtmpfsFilesystem Type Size Used Avail Use% Mounted on/dev/root ext4 3.0G 646M 2.3G 22% //dev/mmcblk0p36 vfat 1.0G 56M 969M 6% /bluetooth/dev/mmcblk0p26 ext4 12M 4.2M 7.4M 36% /dsp/dev/mmcblk0p42 ext4 28M 108K 27M 1% /persist/dev/mmcblk0p25 vfat 95M 19M 77M 20% /firmware/dev/mmcblk0p41 ext4 58M 3.1M 54M 6% /cache/dev/mmcblk0p50 ext4 3.4G 1.4G 2.0G 41% /data/dev/sda1 vfat 15G 15G 199M 99% /media/usb1~# ls -lh /media/usb1/rootfs.ext4-rwxr-xr-x 1 root root 2.1G Aug 1 2020 /media/usb1/rootfs.ext4~# cp /media/usb1/rootfs.ext4 /~# sync /rootfs.ext4~# diff -q /media/usb1/rootfs.ext4 /rootfs.ext4~# reboot~# diff -q /media/usb1/rootfs.ext4 /rootfs.ext4~# echo $?0 总结 df、cp等命令对于产品开发者来说并不是那么可靠的，开发者正是要通过设计正确的系统来保证这些命令能正常工作 不带参数的sync命令是不可靠的，若要确认某个文件写入到存储设备上，最好带上具体的路径。在《UNIX环境高级编程》第三版的3.13节中，对sync类函数有这样的描述：sync函数只是将所有修改过的块缓冲区排入写队列，然后就返回，它并不等待实际写磁盘操作结束。不带参数的sync命令调用这个函数。fsync函数只对由文件描述符fd指定的一个文件起作用，并且等待写磁盘操作结束才返回。fdatasync函数类似于fsync，但它只影响文件的数据部分。 若使用mkfs.XXX去格式化分区，这些命令都能正确识别分区大小，并格式化为恰当的文件系统 参考 《UNIX环境高级编程》第三版","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.sfysoft.com/categories/操作系统/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.sfysoft.com/tags/Linux/"}],"keywords":[{"name":"操作系统","slug":"操作系统","permalink":"https://www.sfysoft.com/categories/操作系统/"}]},{"title":"Git使用问题与解决方法","slug":"Git-Issues-and-Solution","date":"2020-07-29T21:43:06.000Z","updated":"2023-09-14T05:56:09.710Z","comments":true,"path":"2020/07/29/Git-Issues-and-Solution/","link":"","permalink":"https://www.sfysoft.com/2020/07/29/Git-Issues-and-Solution/","excerpt":"","text":"本文记录一些使用Git过程中遇到的问题及其解决办法，如无特别提及，所用环境为git version 2.25.1/Ubuntu 20.04 x64。 git clone时出现302错误 问题现象 执行命令git clone https://XXX.git test，出现如下提示 123Cloning into 'test'...error: RPC failed; HTTP 302 curl 22 The requested URL returned error: 302fatal: the remote end hung up unexpectedly 解决过程 首先了解HTTP 302表示的是什么错误，通过学习了解到302错误表示被请求的资源暂时转移（Moved temporatily），服务器端会给出一个转移后的URL，此后，客户端应按照转移后的URL再次请求，一般浏览器都会自动处理这种情况。 那么git是如何处理http[s]的呢？从此条日志可以看到git使用了curl或libcurl来做http[s]的客户端的，另外回顾使用sudo apt-get install git命令安装git时，也可以看到安装了git、git-man、libcurl3-gnutls这3个包，因此，可以从curl的使用入手分析，先查看了git clone的手册（man git-clone），没有找到什么有用信息，继续看curl手册（man curl），在查找302这个关键时发现-L选项正是处理此种情况的，那么是不是因为git没有使用这样的选项才报错，应当如何指定这种选项？带着这种疑问继续查看git配置手册（man git-config），在检索了带有关键字curl或http的配置后，发现配置项http.followRedirects描述的是如何处理资源重定向的，按照文档描述，默认配置initial只跟随一次，而设置为true后会跟随任意重定向，因此，将此值设为true（git config --global http.followRedirects true）继续尝试，结果命令正常完成，问题得到解决。 在解决此问题的过程中，还了解到将GIT_CURL_VERBOSE环境变量设置为1（export GIT_CURL_VERBOSE=1）可以观察到整个curl处理http[s]的全过程，是个调试git报curl相关错误的方法。除此之外，导出另外两个环境变量（export GIT_TRACE_PACKET=1和export GIT_TRACE=1）可以观察到更详细的过程，可以按需尝试一下。 git clone时出现curl 56 GnuTLS recv error (-9)错误 问题现象 执行命令git clone https://github.com/vim/vim.git，出现如下提示 123456789Cloning into 'vim'...remote: Enumerating objects: 172504, done.remote: Counting objects: 100% (27/27), done.remote: Compressing objects: 100% (17/17), done.error: RPC failed; curl 56 GnuTLS recv error (-9): Error decoding the received TLS packet.error: 3785 bytes of body are still expectedfetch-pack: unexpected disconnect while reading sideband packetfatal: early EOFfatal: fetch-pack: invalid index-pack output 解决过程 多次尝试发现，有的时候网速较快时也能成功，而从网络上收集来的资料看，GnuTLS方式出现了各种各样的问题，可以自行编译并使用OpenSSL。在Ubuntu上，由于官方包将git安装在/usr/bin/下面，保持官方的话，自行编译可以将prefix设为/usr/local，/usr/local/bin通常是优先于/usr/bin的，如此我们默认先使用自行编译的git，而用apt命令安装的命令和手册仍保留，以下是一个编译过程： 123456git clone git://git.kernel.org/pub/scm/git/git.gitgit checkout v2.9.5sudo apt install -y libssl-dev zlib1g-dev libexpat1-dev tcl gettext # 根据下面的编译错误提示，使用apt-file search和apt找到缺失的库并安装sudo apt install -y libcurl4-openssl-dev # 关键，不使用libcurl4-gnutls-dev或libcurl4-nss-devmake prefix=/usr/local/sudo make prefix=/usr/local install 参考资料 man git-clone man curl man git-config","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"},{"name":"Git","slug":"Git","permalink":"https://www.sfysoft.com/tags/Git/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"GCC交叉编译器的命名与用法","slug":"Cross-Build-Compiler-Name-Usage","date":"2019-07-15T02:21:37.000Z","updated":"2023-09-14T05:55:05.343Z","comments":true,"path":"2019/07/15/Cross-Build-Compiler-Name-Usage/","link":"","permalink":"https://www.sfysoft.com/2019/07/15/Cross-Build-Compiler-Name-Usage/","excerpt":"","text":"本文内容，分别在Ubuntu 14.04/18.04使用arm-none-eabi-gcc 4.8.2/6.3.1、arm-linux-gnueabi[hf]-gcc 4.8.4/7.4.0、aarch64-linux-gnu-gcc 4.8.4/7.4.0、arm-linux-androideabi-gcc 4.7.3/4.8验证过。 在Android或是嵌入式开发时，常常会用到交叉编译器，这些编译器的命名有arm-linux-androideabi-gcc，arm-eabi-gcc，在Ubuntu上，也有gcc-arm-linux-gnueabihf、gcc-arm-linux-gnueabi、gcc-arm-none-eabi这些包可供安装，那么，这些不同名字的编译器有什么区别，用在什么场景？这就是本文要说明的。 命名规则 一般来讲，gcc交叉编译器的命名有这几部分组成[arch-][vendor-][os-][eabi-]name，其中： arch：指体系结构，例如arm、x86_64、aarch64。 vendor：指工具链提供商。 os：指目标操作系统，如果这一部分没有或者为none，则是为编译bootloader这种不依赖操作系统接口的软件制作的，经常可以看到的是linux，即编译器可用来生成运行在Linux系统上的程序。 eabi：全称为Embedded Application Binary Interface（应用二进制接口），定义了数据类型大小、布局和对齐、文件格式、调用约定等一系列底层接口，使用某一EABI编译好的目标代码在兼容这一EABI的系统中无需改动即可运行，一般来讲，这个也代表了使用的C库是什么。 这一部分可能还会出现hf后缀，用来指定浮点数二进制接口，实际影响到的是gcc的-mfloat-abi选项默认值。-mfloat-abi有三种值，soft表示浮点运算不使用FPU，而是使用软件来实现，并使用软件浮点调用约定，这是不带hf的编译器的默认值。softfp表示允许浮点运算使用硬件浮点指令，但仍旧使用软件浮点调用约定。hard表示使用硬件浮点指令，并使用FPU特定的调用约定，这是带hf后缀的编译器的默认值，通常也只有带hf后缀的编译器才能指定这个值。软件浮点和硬件浮点，在链接时是不能兼容的，整个程序必须使用相同的ABI，并链接兼容的库才行，由于soft和softfp都使用软件浮点调用约定，因此，这两个选项编译出来的目标文件和库是兼容的。而hard模式不与其它两种选项兼容。-mfloat-abi选项的具体验证，可以在命令行选项中指定-v来查看一下输出。 name：工具链中具体的程序名字，例如gcc、as、nm等。 示例 arm-none-eabi-gcc/arm-eabi-gcc 用于编译ARM架构的程序，包括bootloader、ARM Linux kernel，不适用于编译ARM Linux应用程序，因其不支持那些与操作系统关系密切的函数，比如各种系统调用。arm-eabi-gcc一般出现在Android源码树中，不适宜于用在其它项目，所需要的头文件和库等都没有打包在一起。 arm-linux-androideabi-gcc 用于编译ARM架构的程序，主要用于Android源码里的应用程序，因为它使用了Android的bionic库，要用于其它目的需要进行较复杂的处理。Ubuntu 14.04提供了一个安装后直接可用的包gcc-arm-linux-androideabi，但后续Ubuntu版本没有再看到。 aarch64-linux-android-gcc 用于编译ARM 64位架构的程序，主要用于Android源码里的应用程序，因为它使用了Android的bionic库，要编译其它类型的程序需要进行较复杂的处理。 aarch64-linux-gnu-gcc 用于编译ARM 64位架构的程序，包括bootloader、ARM Linux kernel、ARM Linux应用程序，使用GNU C库及其调用约定。 arm-linux-gnueabihf-gcc 用于编译ARM架构的程序，包括bootloader、ARM Linux kernel、ARM Linux应用程序，使用GNU C库及其调用约定。浮点数运算默认使用hard模式。 参考 armel、armhf和arm64区别选择 GCC online documentation","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}],"tags":[{"name":"Tool Chain","slug":"Tool-Chain","permalink":"https://www.sfysoft.com/tags/Tool-Chain/"},{"name":"GCC","slug":"GCC","permalink":"https://www.sfysoft.com/tags/GCC/"}],"keywords":[{"name":"开发工具","slug":"开发工具","permalink":"https://www.sfysoft.com/categories/开发工具/"}]},{"title":"apt-get update出现NO_PUBKEY提示的解决方法","slug":"Apt-No-Public-Key","date":"2019-07-11T05:43:41.000Z","updated":"2023-09-14T05:55:05.331Z","comments":true,"path":"2019/07/11/Apt-No-Public-Key/","link":"","permalink":"https://www.sfysoft.com/2019/07/11/Apt-No-Public-Key/","excerpt":"","text":"问题现象 在执行apt-get update时，出现如下提示： 1The following signatures couldn't be verified because the public key is not available: : NO_PUBKEY B5B7720097BB3B58 解决办法 一般来讲，可以直接从key server获取缺失的公钥，Debian系统命令如下： 1sudo apt-key adv --keyserver keyring.debian.org --recv-keys B5B7720097BB3B58 Ubuntu系统命令如下： 1sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys B5B7720097BB3B58 不同系统的区别就是换了个key server，除上述keyserver外，其它可用的key server还有 12keys.gnupg.netpool.sks-keyservers.net 这些server同时还提供了Web页来搜索key的功能，https://sks-keyservers.net/overview-of-pools.php给出了一个server pool列表。 此外，有些较旧的系统，可能用上述命令也获取不到缺失的公钥，此时，可以使用下面描述的方法，这种方法事实上一次安装了许多的公钥。用下列命令找出相应系统的keyring包，然后安装： 12345678$ apt-cache search keyring | grep \"debian\" debian-archive-keyring - GnuPG archive keys of the Debian archivedebian-edu-archive-keyring - GnuPG archive keys of the Debian Edu archivedebian-keyring - GnuPG keys of Debian Developers and Maintainersdebian-ports-archive-keyring - GnuPG archive keys of the debian-ports archiveemdebian-archive-keyring - GnuPG archive keys for the emdebian repositoryneurodebian-archive-keyring - neuroscience-oriented distribution - GnuPG archive keys$ sudo apt-get install debian-archive-keyring debian-keyring debian-ports-archive-keyring 一般安装上面3个包即可解决，如果不行，可以再把其它几个也装上。Ubuntu系统的话，尝试以下命令： 1234567$ apt-cache search keyring | grep \"ubuntu\"ubuntu-cloudimage-keyring - GnuPG keys of the Ubuntu Cloud Image builderubuntu-extras-keyring - GnuPG keys of the Ubuntu extras archiveubuntu-keyring - GnuPG keys of the Ubuntu archiveubuntu-cloud-keyring - GnuPG keys of the Ubuntu Cloud Archiveubuntukylin-keyring - GnuPG keys of the Ubuntu Kylin archive$ sudo apt-get install ubuntu-keyring ubuntu-extras-keyring 同样地，如果安装的这2个包不行，就把其它的也装上。","categories":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}],"tags":[{"name":"Debian","slug":"Debian","permalink":"https://www.sfysoft.com/tags/Debian/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.sfysoft.com/tags/Ubuntu/"}],"keywords":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}]},{"title":"Hexo使用问题与解决方法","slug":"Hexo-Issues-and-Solution","date":"2019-06-26T02:09:10.000Z","updated":"2023-09-14T05:55:05.351Z","comments":true,"path":"2019/06/26/Hexo-Issues-and-Solution/","link":"","permalink":"https://www.sfysoft.com/2019/06/26/Hexo-Issues-and-Solution/","excerpt":"","text":"本文记录一些使用Hexo过程中遇到的麻烦问题，一般的安装和使用教程可以参考Hexo官方文档，这里就不写了。验证环境为Hexo v3.9.0/NodeJS v10.15.3/Windows 10 1803 x64和Hexo v3.9.0/NodeJS v12.2.0/Ubuntu 18.04 x64。 图片引用问题 问题现象 在post_asset_folder配置为true的情况下，若生成一篇名为test的文章，Hexo会自动帮我们创建test.md和test目录。如果图片test.png放在test目录下，并在test.md中通过![test](test.png)这样的代码引用图片，那么，在安装了hexo-asset-image插件的情况下，Hexo生成的HTML中，图片的引用路径如下： 1&lt;meta property=&quot;og:image&quot; content=&quot;https://www.sfysoft.com/.com//test.png&quot;&gt; 这个路径是错误的，根本引用不到图片，浏览器就显示不出来。如果没有安装hexo-asset-image插件，生成的HTML中，图片的引用路径如下： 1&lt;meta property=&quot;og:image&quot; content=&quot;https://www.sfysoft.com/2019/06/26/test/test.png&quot;&gt; 这个路径是正确的，发布后，在浏览器中能正确显示，但一般在Markdown编辑器中显示不了，无法实现所见即所得，如果使用![test](test/test.jpg)这样的代码引用，则一般在Markdown编辑器中能即时显示，但生成的文章显示不了，查看文章HTML源代码可以看到，图片引用路径变成了这样： 1&lt;meta property=&quot;og:image&quot; content=&quot;https://www.sfysoft.com/2019/06/26/test/test/test.png&quot;&gt; test路径重复了，无法引用到正确的路径。 解决办法 虽然网络上有许多文章提到要安装hexo-asset-image插件，但真实的情况是，这个插件在使用上述方式引用图片时，并没有按预期工作，而在没有hexo-asset-image插件的情况下，图片路径也能正确生成。经过研究，发现一种可以正确引用图片的方法： 卸载hexo-asset-image插件 使用![test](test.png)这样的方式，而非![test](test/test.jpg)的方式引用图片 使用支持设置图片引用根目录的Markdown编辑器来编辑md文件，例如，使用Typora编辑器的话，就可以在md文件的Front-matter部分，加上typora-root-url: test这条指令，来指示图片引用的基准目录为文件同级路径test。这样的话，在Typora编辑器中能正确显示图片，生成的HTML中，路径也是对的。 另外，为了解决这个问题，分析了代码，图片路径的生成，是在node_modules/hexo/lib/plugins/helper/open_graph.js的openGraphHelper函数中做的，其中有一段images = images.map(path =&gt;...);的代码做了这个工作，想从源码级解决的话，可以从这里入手。","categories":[{"name":"软件使用","slug":"软件使用","permalink":"https://www.sfysoft.com/categories/软件使用/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://www.sfysoft.com/tags/Hexo/"}],"keywords":[{"name":"软件使用","slug":"软件使用","permalink":"https://www.sfysoft.com/categories/软件使用/"}]},{"title":"Samba使用问题与解决方法","slug":"Samba-Issues-and-Solution","date":"2019-06-21T07:08:12.000Z","updated":"2023-09-14T05:55:05.355Z","comments":true,"path":"2019/06/21/Samba-Issues-and-Solution/","link":"","permalink":"https://www.sfysoft.com/2019/06/21/Samba-Issues-and-Solution/","excerpt":"","text":"Windows无法访问Samba共享的符号链接指向的目录 问题现象 Linux/Unix Samba共享的符号链接指向了目录，在Windows上能看到，但是不能打开。 解决办法 修改/etc/samba/smb.conf文件，在 “[global]” 下加入或修改如下内容： 123follow symlinks = yeswide links = yesunix extensions = no","categories":[{"name":"服务器","slug":"服务器","permalink":"https://www.sfysoft.com/categories/服务器/"}],"tags":[{"name":"Samba","slug":"Samba","permalink":"https://www.sfysoft.com/tags/Samba/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"https://www.sfysoft.com/categories/服务器/"}]},{"title":"家庭网关设备的隐藏账户和密码","slug":"HomeGateway-Hidden-Username-Password","date":"2019-06-20T10:41:38.000Z","updated":"2023-09-14T05:55:05.351Z","comments":true,"path":"2019/06/20/HomeGateway-Hidden-Username-Password/","link":"","permalink":"https://www.sfysoft.com/2019/06/20/HomeGateway-Hidden-Username-Password/","excerpt":"","text":"在安装家庭宽带时，运营商会给用户一个网关设备，现在常见的就是光猫。这些设备，会提供给用户一个普通账户和密码，可以进行一些有限的修改，在中国电信的设备上，这个账户是useradmin。然而，总是有些玩家想要更大程度地控制自己的设备，启用更多的功能，于是，出现了各种破解的方法，找出了不同的设备具有的隐藏账户和密码。这里，记录一些常见设备的隐藏账户及其相关的配置页面。 一般来说，隐藏的账户会有两个，一个是运营商管理账户，可以修改大多数路由配置功能，在中国电信的设备上，这个账户是telecomadmin；一个是工厂账户，它可以修改设备管理的底层功能，这个账户根据设备生产商有所不同。以下列出收集到的设备信息。 账户与配置页 烽火HG220GS 硬件版本为BCM.V2.0且软件版本为E00D1.00M5002的设备已验证有效。 启用隐藏账户页面：http://192.168.1.1/logoffaccount.html。如果打开这个页面需要登录，用普通账户登录即可，然后可以在这个页面里启用工厂账户。没有在此启用的话，即使知道了工厂账户的密码，也是无法登录的。 这个型号的设备，中国电信版本的工厂账户是fiberhomehg2x0，密码是hg2x0。telnet账号是admin，密码是admin。超级用户的密码，需要使用工厂账户登录http://192.168.1.1后，在地址栏里输入http://192.168.1.1/backupsettings.conf下载backupsettings.conf，然后查找Password关键词，在TeleComAccount下面这一行的内容，即是telecomadmin账户经Base64编码后的密码，使用Base64解码工具即可获得原文密码。 HG226G（未经验证） 额外登录页面：http://192.168.1.1/brcm/login.html。一般而言，网关的登录页面是http://192.168.1.1，但有的设备可以通过这个地址登录。 备份配置页面：http://192.168.1.1/brcm/backupsettings.html。此页面提供配置下载功能，从这里下载的配置文件可以找到telecomadmin的密码，密码可能是明文的，也可能是Base64编码后的。 更新配置页面：http://192.168.1.1/brcm/updatesettings.html。这个页面可以上传修改后的配置文件，并更新到设备。 上述几个在/brcm下的页面，登录账户是admin，密码是admin。 这个型号的设备，工厂账户是fiberhomehg2x0，密码是hg2x0。 吉比特CM113-Z（未经验证） 启用隐藏账户页面：http://192.168.1.1/logoffaccount.html（2021-02-02：根据网友(hashwu333)[https://github.com/hashwu333]提供的信息：登录地址应该是：http://192.168.1.1）。如果打开这个页面需要登录，用普通账户登录即可，然后可以在这个页面里启用工厂账户。 这个型号的设备，中国移动版本的超级账户是CMCCAdmin，密码是aDm8H%MdA。工厂账户是fiberhomehg2x0，密码是hg2x0。 烽火HG6821M光猫（未经验证） 启用隐藏账户页面：http://192.168.1.1/logoffaccount.html。如果打开这个页面需要登录，用普通账户登录即可，然后可以在这个页面里启用工厂账户。 文件配置信息地址：http://192.168.1.1/cgi-bin/baseinfoSet.cgi。 临时开启telnet服务页面：http://192.168.1.1/cgi-bin/telnetenable.cgi?telnetenable=1。 这个型号的设备，中国移动版本的超级账户是CMCCAdmin，密码是aDm8H%MdA。工厂账户是fiberhomehg2x0，密码是hg2x0。telnet账号是root，密码是hg2x0或abcd。 使用工厂账户登录后，可在维护页面，一键下载配置目录下所有文件。解压后打开param.xml可以查询运营商管理账户密码。factory.conf文件里则保存了光猫的所有配置信息。 也可以在使用telnet登录设备后，查看/flash/cfg/agentconf/factory.conf文件获得超级用户密码。 如何取得这些信息 查看厂商的说明书 从网络上搜索对应设备型号 从业内人士处了解到 使用普通账户登录后，分析网页的源代码和脚本，例如，从HG220GS设备上登录后，查看源码可以发现如下内容： 12345678910111213141516171819202122232425262728&lt;script language='javascript'&gt; &lt;!-- hide var options = new Array('', 'admin', '1', '2', '1', '', 'CT_E8_C', '1', '', //SUPPORT_SES '0', 'useradmin', 'telecomadmin', 'useradmin', 'fiberhomehg2x0', 'ctinfo.html', 'HG220G', '1', '1', '0', '3', '5' ); createCTMenu(options); initializeDocument(); // done hiding --&gt;&lt;/script&gt; 进一步从脚本menuCT.js找到createCTMenu函数： 1234567891011121314151617181920212223242526272829303132333435function createCTMenu(options) &#123;// var curuser = options[MENU_OPTION_CURUSER];// var sysuser = options[MENU_OPTION_SYSUSER]; var inUseName = options[MENU_OPTION_INUSENAME]; var firstPage = options[MENU_OPTION_FIRSTPAGE]; if(options[MENU_OPTION_FACTORYNAME] == inUseName)&#123; foldersTree = gFld('', 'factorymode.html', true); nodeFactory = insFld(foldersTree, gFld(getMenuTitle(MENU_FACTORY), 'factorymode.html', true)); insFld(nodeFactory, gFld(getMenuTitle(MENU_FACTORY_BASEINFO), 'factorymode.html', true)); menufiberhome(options); &#125; else&#123; foldersTree = gFld('', 'ctinfo.html'); // device info menu nodeStatus = insFld(foldersTree, gFld(getMenuTitle(MENU_STATUS), 'ctinfo.html')); // device summary menu nodeStatusDevice = insFld(nodeStatus, gFld(getMenuTitle(MENU_STS_DEVICE), 'ctinfo.html')); insFld(nodeStatusDevice, gFld(getMenuTitle(MENU_STS_DEV_INFO), 'ctinfo.html')); if(options[MENU_OPTION_ADMINNAME] == inUseName) menuAdmin(options); else if(options[MENU_OPTION_USERNAME] == inUseName) menuUser(options); &#125;​/* if ( curuser == sysuser || curuser == 'admin')​ menuAdmin(options);​ else​ menuUser(options);*/&#125; 进而分析整个menuCT.js文件，就可以知道options数组中出现的useradmin、telecomadmin、useradmin、fiberhomehg2x0分别对应的是INUSENAME、ADMINNAME、USERNAME、FACTORYNAME。 拆开硬件后，自行在主板上接上串口线（一般是TTL四线连接），然后要么按CTRL+C，要么搜索相应型号的telnet用户和密码登录Shell，探索文件系统的内容来分析。","categories":[{"name":"信息安全","slug":"信息安全","permalink":"https://www.sfysoft.com/categories/信息安全/"}],"tags":[{"name":"网络设备","slug":"网络设备","permalink":"https://www.sfysoft.com/tags/网络设备/"}],"keywords":[{"name":"信息安全","slug":"信息安全","permalink":"https://www.sfysoft.com/categories/信息安全/"}]},{"title":"APK编译错误之Error inflating class","slug":"APK-Build-Issue-Error-inflating-class","date":"2019-05-28T07:04:16.000Z","updated":"2023-08-02T00:59:54.689Z","comments":true,"path":"2019/05/28/APK-Build-Issue-Error-inflating-class/","link":"","permalink":"https://www.sfysoft.com/2019/05/28/APK-Build-Issue-Error-inflating-class/","excerpt":"","text":"这里记录的案例，虽说确实是编译原因导致的，但问题真正发生是在运行时。开发工具：Android Studio 3.4.1，运行环境：Android 5.1.1。 问题现象 话说为了选择个文件，使用了第三方库com.leon:lfilepickerlibrary:1.8.0，由于这个库和原来的项目同时引用了com.android.support:appcompat-v7，但版本不一致，可能出现Duplicate class的问题，所以，使用排除传递依赖项的方法，排除了这个库对com.android.support的引用，关于Duplicate class的问题参考这里。在初始的build.gradle里具有这样的配置： 123456789101112131415compileSdkVersion 28 defaultConfig &#123; minSdkVersion 19 targetSdkVersion 28 versionCode 1 versionName &quot;1.0&quot; &#125;dependencies &#123; implementation fileTree(include: [&apos;*.jar&apos;], dir: &apos;libs&apos;) implementation &apos;com.android.support:appcompat-v7:28.0.0&apos; implementation &apos;com.android.support.constraint:constraint-layout:1.1.3&apos; implementation(&apos;com.leon:lfilepickerlibrary:1.8.0&apos;) &#123; exclude group: &apos;com.android.support&apos; &#125;&#125; 编译一切正常，安装到手机上运行并使用这个库提供的功能时，应用出现停止运行，查看logcat，具有如下内容： 12345java.lang.RuntimeException: Unable to start activity ComponentInfo&#123;.../com.leon.lfilepickerlibrary.ui.LFilePickerActivity&#125;: android.view.InflateException: Binary XML file line #62: Error inflating class com.leon.lfilepickerlibrary.widget.EmptyRecyclerView&#125;...Caused by: android.view.InflateException: Binary XML file line #62: Error inflating class com.leon.lfilepickerlibrary.widget.EmptyRecyclerView...Caused by: java.lang.ClassNotFoundException: Didn&apos;t find class &quot;com.leon.lfilepickerlibrary.widget.EmptyRecyclerView&quot; on path: DexPathList... 解决过程 从ClassNotFoundException看起，使用JadX反编译了生成的apk，发现com.leon.lfilepickerlibrary.widget.EmptyRecyclerView确实存在于apk内，路径也完全一致，看来不是这个问题。 在网上搜索Apk ClassNotFoundException和Apk Error inflating class看了一些相关的内容后，发现都和这里的不同。 不得已，回到项目重新思考引用这个库的方式，怀疑可能是依赖存在问题，于是做了以下尝试： 首先，删除了exclude group: 'com.android.support'这一段，这时，Android Studio会在implementation 'com.android.support:appcompat-v7:28.0.0'这一行上会显示红色波浪线，鼠标点击后，即时提示告知：“All com.android.support libraries must use the exact same version specification (mixing versions can lead to runtime crashes). Found versions 28.0.0, 25.0.0.”。可见，这个第三方库引用了com.android.support 25.0.0的版本。 其次，根据提示，把compileSdkVersion、targetSdkVersion、com.android.support:appcompat-v7的版本都从28改到了25后，编译并运行，发现功能正常。 推断依赖存在问题，那么，com.leon:lfilepickerlibrary:1.8.0的依赖到底应该是怎样的呢？查看这个包的pom文件就可以知道了，在本地缓存里（一般是当前用户主目录的.gradle/caches目录下）搜索到对应的pom文件，查看依赖节具有如下内容： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.android.support&lt;/groupId&gt; &lt;artifactId&gt;appcompat-v7&lt;/artifactId&gt; &lt;version&gt;25.0.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.android.support&lt;/groupId&gt; &lt;artifactId&gt;recyclerview-v7&lt;/artifactId&gt; &lt;version&gt;25.0.0&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 这里的内容显示：除了appcompat-v7模块外，这个库还依赖于recyclerview-v7模块，而使用exclude group: 'com.android.support'排除了所有groupId是com.android.support的模块。 了解了原因后，解决起来就简单了，compileSdkVersion、targetSdkVersion、com.android.support:appcompat-v7仍使用28版本，但是在build.gradle的dependencies节里增加一行implementation 'com.android.support:recyclerview-v7:28.0.0'。这里，recyclerview-v7的版本应当和appcompat-v7的版本完全一致。最终，build.gradle中的dependencies按照下面的写法即可： 123456789dependencies &#123; implementation fileTree(include: [&apos;*.jar&apos;], dir: &apos;libs&apos;) implementation &apos;com.android.support:appcompat-v7:28.0.0&apos; implementation &apos;com.android.support:recyclerview-v7:28.0.0&apos; implementation &apos;com.android.support.constraint:constraint-layout:1.1.3&apos; implementation(&apos;com.leon:lfilepickerlibrary:1.8.0&apos;) &#123; exclude group: &apos;com.android.support&apos; &#125;&#125; 最后，这些模块都可以通过浏览https://maven.google.com找到，也可以在Android Studio中找到并添加，操作路径是：选中相应的Project，按F4打开Project Structure，点击左侧的Dependencies，然后添加Library Dependency，在出现的对话框中输入com.android.support并搜索，搜索结果出来后，选中recyclerview-v7对应的版本即可添加，具体如下图： 除此之外，不直接添加对recyclerview-v7的引用，而是仅排除可能产生冲突的模块也是可以的，使用exclude时指定module即可，在这里，就是如下列所示： 123implementation(&apos;com.leon:lfilepickerlibrary:1.8.0&apos;) &#123; exclude group: &apos;com.android.support&apos;, module: &apos;appcompat-v7&apos;&#125; 但是这会导致引用了不同版本的com.android.support组的模块，因此，并不推荐这种方式。","categories":[{"name":"软件开发","slug":"软件开发","permalink":"https://www.sfysoft.com/categories/软件开发/"}],"tags":[{"name":"Android应用","slug":"Android应用","permalink":"https://www.sfysoft.com/tags/Android应用/"},{"name":"Android Studio","slug":"Android-Studio","permalink":"https://www.sfysoft.com/tags/Android-Studio/"}],"keywords":[{"name":"软件开发","slug":"软件开发","permalink":"https://www.sfysoft.com/categories/软件开发/"}]},{"title":"APK编译错误之Duplicate class","slug":"APK-Build-Issue-Duplicate-class","date":"2019-05-24T07:07:12.000Z","updated":"2023-08-02T00:59:54.689Z","comments":true,"path":"2019/05/24/APK-Build-Issue-Duplicate-class/","link":"","permalink":"https://www.sfysoft.com/2019/05/24/APK-Build-Issue-Duplicate-class/","excerpt":"","text":"为了快速开发，不免使用些第三方库，这时，第三方库的依赖包与我们原来引用的同名包就可能存在版本冲突。这里，记录一个在Android Studio 3.4.1中引用了某第三方库后，编译时出现Duplicate class的问题及其解决办法。编译输出如下图： 意思是，相同的类出现在了两个不同版本的com.android.support包里。同时，查看build.gradle时发现有如下图提示： 这里的意思是我们要引用相同版本的com.android.support包。回想出现问题前做过什么，也就是添加了一个第三方库com.vincent.filepicker:MultiTypeFilePicker:1.0.8来选择文件，考虑到项目原来用到的com.android.support 是28.0版本，那么日志中提到的com.android.support 26.1版本，就是这个第三方库所引用的版本了。找到问题所在后，接下来考虑解决办法，有两种思路：一是让项目使用第三方库引用的com.android.support版本；一种是第三方库使用原项目引用的com.android.support版本。 使用第三方库引用的com.android.support版本 使用这种方法，只要在build.gradle中，把以下三项的版本修改为第三方库引用的版本即可： 123compileSdkVersion 28targetSdkVersion 28implementation &apos;com.android.support:appcompat-v7:28.0.0&apos; 修改为 123compileSdkVersion 26targetSdkVersion 26implementation &apos;com.android.support:appcompat-v7:26.1.0&apos; 修改完成之后，在此案例中即可成功编译并使用。但如果我们需要使用com.android.support高版本的一些特性，这种方法可能就不能用了，因此，我们可以考虑使用下一种方法。 使用原项目引用的com.android.support版本 这里，用到implementation配置项的一个特性exclude，来排除传递依赖项。在这个例子里，仅需把 1implementation &apos;com.vincent.filepicker:MultiTypeFilePicker:1.0.8&apos; 修改为 123implementation(&apos;com.vincent.filepicker:MultiTypeFilePicker:1.0.8&apos;) &#123; exclude group: &apos;com.android.support&apos;&#125; 即可排除com.vincent.filepicker:MultiTypeFilePicker:1.0.8所指定的com.android.support版本，这样，项目中使用com.android.support接口的地方，包括com.vincent.filepicker:MultiTypeFilePicker:1.0.8，只会链接到28版本。然而，如果第三方库用到了的某些接口，在我们指定的版本上已不再可用时，这种方法就不能用了。当然，这种情况很少见，如果出现，那说明这个库也该被淘汰了。 参考 Android Studio User Guide——Add build dependencies节中关于排除依赖的描述","categories":[{"name":"软件开发","slug":"软件开发","permalink":"https://www.sfysoft.com/categories/软件开发/"}],"tags":[{"name":"Android应用","slug":"Android应用","permalink":"https://www.sfysoft.com/tags/Android应用/"},{"name":"Android Studio","slug":"Android-Studio","permalink":"https://www.sfysoft.com/tags/Android-Studio/"}],"keywords":[{"name":"软件开发","slug":"软件开发","permalink":"https://www.sfysoft.com/categories/软件开发/"}]},{"title":"Ubuntu远程桌面连接","slug":"Ubuntu-RemoteDesktop","date":"2019-04-22T16:00:00.000Z","updated":"2019-05-19T16:00:00.000Z","comments":true,"path":"2019/04/22/Ubuntu-RemoteDesktop/","link":"","permalink":"https://www.sfysoft.com/2019/04/22/Ubuntu-RemoteDesktop/","excerpt":"","text":"本文在Ubuntu 18.04上测试通过。 在Ubuntu上使用远程桌面的方式也有不少，如果是Ubuntu桌面版系统，系统自带的设置即可配置共享桌面，本文讲述的，则是在Ubuntu Server版本上安装并使用远程桌面的方式，相对VNC之类的来讲，也算是一种比较简单易行的方式。 所涉及到的软件包括xrdp，dde(Deepin Desktop Environment，来自Deepin Linux，比较美观)，桌面环境使用其它的也是可以的，以下是详细的操作步骤。 第一步、配置系统源并更新 sudo add-apt-repository ppa:leaeasy/dde # 用于安装dde sudo apt-get update 第二步、安装所需软件 sudo apt-get install dde # 这里也可以安装其它的桌面环境，如xubuntu-desktop sudo apt-get install xrdp 第三步、修改Xsession配置 vim /etc/X11/Xsession 在文件尾的&quot;exit 0&quot;这一行前加上一行 lightdm-session 如果是使用其它的桌面环境，就用相应的X session替代，例如：使用xubuntu-desktop的用xfce4-session替代。 第四步、重启xrdp服务 service xrdp restart 第五步、连接 这里可以使用Windows自带的远程桌面连接程序mstsc，输入目标的IP后点“连接”按钮，在出现的登录界面，Session选择默认的Xorg，然后username和password栏里分别输入自己的用户名和密码即可。","categories":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.sfysoft.com/tags/Ubuntu/"}],"keywords":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}]},{"title":"Ubuntu扩展软件包——PPA的使用","slug":"Ubuntu-UsingPPA","date":"2019-04-21T16:00:00.000Z","updated":"2019-05-19T16:00:00.000Z","comments":true,"path":"2019/04/21/Ubuntu-UsingPPA/","link":"","permalink":"https://www.sfysoft.com/2019/04/21/Ubuntu-UsingPPA/","excerpt":"","text":"什么是PPA PPA，全称为Personal Package Archives，也就是个人软件包集。 在Ubuntu系统上，有一些软件包由于各种原因，不能进入官方的软件仓库，为了方便Ubuntu用户使用，Ubuntu母公司Canonical有限公司架设了网站launchpad.net来提供PPA，允许用户上传软件，建立自己的软件仓库，当然，也可以分享给其它人使用。 如何使用PPA 一般来讲，使用PPA具有如下步骤： 在https://launchpad.net网站搜索你要的软件包 在搜索结果列表中，找到你需要的那个软件包的链接 打开所需软件包的链接后，在“Adding this PPA to your system”这一节中查看使用此PPA的指令，并在Ubuntu系统中逐条执行，此后即可使用此PPA里的软件包 “PPA description”这一节里，可能提供了安装此包所需的指令，如果在“PPA description”这一节里没有，那就从“Overview of published packages”找到包名，并执行apt-get install packageName即可 实例：在Ubuntu中安装Deepin Linux的桌面环境 用浏览器打开https://launchpad.net，在“Search Launchpad”按钮旁边的输入框里输入“deepin desktop”或“deepin”，出来一串结果，排在第一位的即是“Deepin Desktop Environment : leaeasy - Launchpad”，打开这个链接，在“Adding this PPA to your system”这一节里，可以看到如下指令： sudo add-apt-repository ppa:leaeasy/dde sudo apt-get update 同时，在“PPA description”这一节里，也提供了完整的安装Deepin桌面环境的指令，把这些指令在Ubuntu系统中执行并根据提示操作即可： sudo add-apt-repository ppa:leaeasy/dde sudo apt-get update sudo apt-get install dde 在“Overview of published packages”下面，则列出了此用户发布的所有软件包。","categories":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://www.sfysoft.com/tags/Ubuntu/"}],"keywords":[{"name":"Linux使用","slug":"Linux使用","permalink":"https://www.sfysoft.com/categories/Linux使用/"}]}]}